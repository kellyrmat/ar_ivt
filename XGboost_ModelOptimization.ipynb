{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Bias-Variance Tradeoff\n",
    "\n",
    "This notebook evaluates the changes in model's bias-variance as the testing-training split is varied. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from flaml.automl.ml import sklearn_metric_loss_score\n",
    "from xgboost import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flaml import AutoML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting and Model Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model_metrics(actual, pred):\n",
    "    MSE = mean_squared_error(actual, pred) # root mean squared error\n",
    "    RMSE = np.sqrt(MSE) # root mean squared error\n",
    "    actual_mean = np.mean(actual) # calculate the mean for use below\n",
    "    RRMSE = 100 * RMSE / actual_mean # relative root mean squared error\n",
    "    R2 = r2_score(actual, pred) # coefficient of determination\n",
    "    return RMSE, RRMSE, R2\n",
    "\n",
    "def scatter_plot(y_test, y_pred_test, title):\n",
    "  # Use the model metrics function to calculate RMSE, RRMSE, and R2\n",
    "    RMSE, RRMSE, R2 = reg_model_metrics(y_test, y_pred_test)\n",
    "  # Initialize the figure and axis\n",
    "    fig,ax = plt.subplots(dpi=350)\n",
    "  # Scatter the y_test vs y_pred_testicted values\n",
    "    ax.scatter(y_test, y_pred_test, edgecolors=(0,0,0))\n",
    "  # Plot the line of perfect fir\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "  # Make a few pieces of text that give the values of R2, RMSE, and RRMSE\n",
    "    text = r\"R2 = %.2f\" % (R2);text += \"\\n\"; text += r\"RMSE = %.2f\" % (RMSE); text += \"\\n\"\n",
    "    text += r\"RRMSE = %.2f\" % (RRMSE) +'%'\n",
    "  # Add the text values to a plot at a particular place on the axis within a box\n",
    "    plt.annotate(text, xy=(0.05, 0.85), xycoords='axes fraction',color='black', fontsize=10,\n",
    "                 bbox=dict(facecolor='none',edgecolor='red'))\n",
    "  # Set the x-axis label\n",
    "    ax.set_xlabel('Actual Average AR IVT')\n",
    "  # Set the y-axis label\n",
    "    ax.set_ylabel('Predicted Average AR IVT')\n",
    "  # Set the plot title\n",
    "    ax.set_title(title)\n",
    "  # Set the background color\n",
    "    fig.patch.set_facecolor('white')\n",
    "  # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_hyperparameter_search(X_train,y_train):\n",
    "\n",
    "\n",
    "    # Initialize the automated pipeline\n",
    "    automl = AutoML()\n",
    "\n",
    "\n",
    "    # Set of the pipeline parameters\n",
    "    settings = {\n",
    "        \"time_budget\": 180,  # total running time in seconds, the longer the better?\n",
    "        \"metric\": 'r2',  # primary metrics for regression can be chosen from: ['mae','mse','r2']; Let's do coefficient of determination now\n",
    "        \"estimator_list\": ['xgboost'],  # pick XGboost as from the list of ML learners in FLAML\n",
    "        \"task\": 'regression',  # task type\n",
    "        \"log_file_name\": 'AR_IVT_fromTCP.log',  # flaml log file\n",
    "        \"seed\": 42,  # random seed (og)\n",
    "    }\n",
    "\n",
    "    # Fit the model iteratively using XGboost\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    optimal_hyperparameters = automl.best_config\n",
    "\n",
    "    return optimal_hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias-Variance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_model(x,y,train_split_percent,optimal_hyperparameters):\n",
    "\n",
    "    \"\"\"\n",
    "    Splits the X & Y dataframes according to the percentage supplied,\n",
    "    sets up an XGboosted regression tree using optimal hyperparameters, \n",
    "    and returns model test/train performance scores (r2).\n",
    "    \"\"\"\n",
    "\n",
    "    #\n",
    "    # Seperate into Test-Train splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,train_size=train_split_percent,random_state=42, shuffle=True)\n",
    "\n",
    "    #\n",
    "    # Build the XGB regression model using the optimized hyperparameters\n",
    "    xgb_reg = XGBRegressor(**optimal_hyperparameters)\n",
    "\n",
    "    # Train the XGboosted regression model\n",
    "    xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Make some predictions\n",
    "    y_pred_te = xgb_reg.predict(X_test) # On the testing split\n",
    "    y_pred_tr = xgb_reg.predict(X_train) # On the training split\n",
    "\n",
    "    #\n",
    "    # Calculate some evaluation metrics on the testing set\n",
    "    r2_te = r2_score(y_pred_te,y_test)\n",
    "    # \n",
    "    # And calculate on the training set, too\n",
    "    r2_tr = r2_score(y_pred_tr,y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    print('Testing r2', '=', r2_te) \n",
    "    print('Training r2', '=', r2_tr) \n",
    "\n",
    "\n",
    "\n",
    "    return r2_tr, r2_te \n",
    "\n",
    "\n",
    "def bias_variance_tradeoff_params(x,y,optimal_hyperparameters,test_splits):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds lists of testing & training performance scores modulated by \n",
    "    the test-train split percentage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up the output lists\n",
    "    test_bias = []\n",
    "    train_bias = []\n",
    "\n",
    "    # Iterate through each train-test split value\n",
    "    for split in test_splits:\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x,y,train_size=split,random_state=42, shuffle=True)\n",
    "        optimal_hyperparameters =   optimal_hyperparameter_search(X_train,y_train)\n",
    "\n",
    "        # Setup, train, and test the XGBregression model according to the split\n",
    "        r2_tr, r2_te  = run_model(x,y,split,optimal_hyperparameters)\n",
    "\n",
    "        test_bias.append(r2_te) # Evaluation metrics for each train-test split value\n",
    "        train_bias.append(r2_tr)\n",
    "\n",
    "\n",
    "    \n",
    "    return test_bias, train_bias\n",
    "\n",
    "def bias_variance_plot(test_bias,train_bias,train_split_percentages):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot the coefficient of determination as modulated by the testing-training split\n",
    "    \"\"\"\n",
    "\n",
    "    # Initiate the plot\n",
    "    fig,ax = plt.subplots(dpi=150)\n",
    "\n",
    "    # Plot the testing and training coefficient of determination \n",
    "    plt.plot(test_bias,label='Testing')\n",
    "    plt.plot(train_bias,label='Training')\n",
    "\n",
    "    # Make the labels from the array of splitting ratios\n",
    "    labels = [str(round(pct,2)) for pct in train_split_percentages]\n",
    "    plt.xticks(ticks = range(0,len(labels)),labels = labels) # Set the xtick labels with those percentages\n",
    "\n",
    "    # Give the plot a title\n",
    "    plt.title('Coefficient of Determination b/w Testing & Training Splits')\n",
    "    plt.legend() # Add the legend\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataframe and identify predictors/predictand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Read the atmospheric river teleconnection pattern dataframe\n",
    "ar_tcp = pd.read_csv(\"C:/Users/kellyrm/Desktop/Research/Atmospheric River Characteristics-Teleconnection Patterns/AR_Climo_withTCP_andTrackParams.csv\")\n",
    "\n",
    "#\n",
    "# Add monthly information to the dataframe\n",
    "ar_tcp['month'] = pd.to_datetime(ar_tcp['datetime']).dt.month \n",
    "\n",
    "#\n",
    "# Grab the dataframe values\n",
    "y = ar_tcp['strength'] # Want to predict the AR's average IVT\n",
    "\n",
    "x = ar_tcp[['BulkAxisDi','SSD_Theta','centroid_y', 'centroid_x', 'PMM', 'QBO', 'MEI', 'Phase','Curvature', 'Displacement','origin_lat', 'origin_lon',\n",
    "       'Amplitude', 'pna_index_cdas', 'nao_index_cdas','month']] # Using physical characteristics contextualized within a synoptic environment using teleconnection pattern indices\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate the testing percentage splits we'll use to evaluate the bias-variance relationship**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_percentages = np.arange(0.5,1,0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up XGboost regression tree model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of hyperparameter tuning from FLAML in XGboost_model.ipynb\n",
    "best_hyperparams = {'n_estimators': 1494, 'max_leaves': 115, 'min_child_weight': 0.28113269299604704,\n",
    "                             'learning_rate': 0.091294396880665, 'subsample': 0.9077443769253482,\n",
    "                             'colsample_bylevel': 0.969129617566699, 'colsample_bytree': 1.0, 'reg_alpha': 0.01044892965208733,\n",
    "                               'reg_lambda': 5.262002821526985}\n",
    "\n",
    "# Build the XGboost regression model using the hperparameters from FLAML above\n",
    "xgb_reg = XGBRegressor(**best_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 08-28 12:22:44] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:22:44] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:22:44] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:22:44] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2344} INFO - Estimated sufficient time budget=1885s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2391} INFO -  at 0.3s,\testimator xgboost's best error=9.9887,\tbest estimator xgboost's best error=9.9887\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2391} INFO -  at 0.4s,\testimator xgboost's best error=9.9887,\tbest estimator xgboost's best error=9.9887\n",
      "[flaml.automl.logger: 08-28 12:22:44] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2391} INFO -  at 0.6s,\testimator xgboost's best error=6.6951,\tbest estimator xgboost's best error=6.6951\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.6951,\tbest estimator xgboost's best error=6.6951\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2391} INFO -  at 1.0s,\testimator xgboost's best error=0.6364,\tbest estimator xgboost's best error=0.6364\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.6364,\tbest estimator xgboost's best error=0.6364\n",
      "[flaml.automl.logger: 08-28 12:22:45] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:46] {2391} INFO -  at 1.8s,\testimator xgboost's best error=0.5262,\tbest estimator xgboost's best error=0.5262\n",
      "[flaml.automl.logger: 08-28 12:22:46] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:47] {2391} INFO -  at 2.8s,\testimator xgboost's best error=0.5152,\tbest estimator xgboost's best error=0.5152\n",
      "[flaml.automl.logger: 08-28 12:22:47] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:47] {2391} INFO -  at 3.4s,\testimator xgboost's best error=0.5152,\tbest estimator xgboost's best error=0.5152\n",
      "[flaml.automl.logger: 08-28 12:22:47] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:48] {2391} INFO -  at 4.1s,\testimator xgboost's best error=0.5152,\tbest estimator xgboost's best error=0.5152\n",
      "[flaml.automl.logger: 08-28 12:22:48] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:50] {2391} INFO -  at 5.6s,\testimator xgboost's best error=0.5152,\tbest estimator xgboost's best error=0.5152\n",
      "[flaml.automl.logger: 08-28 12:22:50] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:50] {2391} INFO -  at 6.0s,\testimator xgboost's best error=0.5152,\tbest estimator xgboost's best error=0.5152\n",
      "[flaml.automl.logger: 08-28 12:22:50] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:53] {2391} INFO -  at 8.9s,\testimator xgboost's best error=0.4182,\tbest estimator xgboost's best error=0.4182\n",
      "[flaml.automl.logger: 08-28 12:22:53] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:22:54] {2391} INFO -  at 10.0s,\testimator xgboost's best error=0.4182,\tbest estimator xgboost's best error=0.4182\n",
      "[flaml.automl.logger: 08-28 12:22:54] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:23:02] {2391} INFO -  at 17.8s,\testimator xgboost's best error=0.3570,\tbest estimator xgboost's best error=0.3570\n",
      "[flaml.automl.logger: 08-28 12:23:02] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:23:04] {2391} INFO -  at 19.8s,\testimator xgboost's best error=0.3570,\tbest estimator xgboost's best error=0.3570\n",
      "[flaml.automl.logger: 08-28 12:23:04] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:23:45] {2391} INFO -  at 60.6s,\testimator xgboost's best error=0.3314,\tbest estimator xgboost's best error=0.3314\n",
      "[flaml.automl.logger: 08-28 12:23:45] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:25:32] {2391} INFO -  at 168.3s,\testimator xgboost's best error=0.3066,\tbest estimator xgboost's best error=0.3066\n",
      "[flaml.automl.logger: 08-28 12:25:54] {2627} INFO - retrain xgboost for 21.8s\n",
      "[flaml.automl.logger: 08-28 12:25:54] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=104,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1081, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:25:54] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:25:54] {1931} INFO - Time taken to find the best model: 168.26500153541565\n",
      "Testing r2 = 0.5612791156350645\n",
      "Training r2 = 0.9719007543332858\n",
      "[flaml.automl.logger: 08-28 12:26:01] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:26:01] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:26:01] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:26:01] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2344} INFO - Estimated sufficient time budget=1646s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2391} INFO -  at 0.2s,\testimator xgboost's best error=9.9924,\tbest estimator xgboost's best error=9.9924\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2391} INFO -  at 0.4s,\testimator xgboost's best error=9.9924,\tbest estimator xgboost's best error=9.9924\n",
      "[flaml.automl.logger: 08-28 12:26:01] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2391} INFO -  at 0.6s,\testimator xgboost's best error=6.6952,\tbest estimator xgboost's best error=6.6952\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.6952,\tbest estimator xgboost's best error=6.6952\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2391} INFO -  at 1.0s,\testimator xgboost's best error=0.6453,\tbest estimator xgboost's best error=0.6453\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.6453,\tbest estimator xgboost's best error=0.6453\n",
      "[flaml.automl.logger: 08-28 12:26:02] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:03] {2391} INFO -  at 1.8s,\testimator xgboost's best error=0.5293,\tbest estimator xgboost's best error=0.5293\n",
      "[flaml.automl.logger: 08-28 12:26:03] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:04] {2391} INFO -  at 2.7s,\testimator xgboost's best error=0.5223,\tbest estimator xgboost's best error=0.5223\n",
      "[flaml.automl.logger: 08-28 12:26:04] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:04] {2391} INFO -  at 3.3s,\testimator xgboost's best error=0.5223,\tbest estimator xgboost's best error=0.5223\n",
      "[flaml.automl.logger: 08-28 12:26:04] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:05] {2391} INFO -  at 4.1s,\testimator xgboost's best error=0.5223,\tbest estimator xgboost's best error=0.5223\n",
      "[flaml.automl.logger: 08-28 12:26:05] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:07] {2391} INFO -  at 5.7s,\testimator xgboost's best error=0.5223,\tbest estimator xgboost's best error=0.5223\n",
      "[flaml.automl.logger: 08-28 12:26:07] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:07] {2391} INFO -  at 6.2s,\testimator xgboost's best error=0.5223,\tbest estimator xgboost's best error=0.5223\n",
      "[flaml.automl.logger: 08-28 12:26:07] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:10] {2391} INFO -  at 9.1s,\testimator xgboost's best error=0.4152,\tbest estimator xgboost's best error=0.4152\n",
      "[flaml.automl.logger: 08-28 12:26:10] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:11] {2391} INFO -  at 10.3s,\testimator xgboost's best error=0.4152,\tbest estimator xgboost's best error=0.4152\n",
      "[flaml.automl.logger: 08-28 12:26:11] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:20] {2391} INFO -  at 18.5s,\testimator xgboost's best error=0.3516,\tbest estimator xgboost's best error=0.3516\n",
      "[flaml.automl.logger: 08-28 12:26:20] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:26:22] {2391} INFO -  at 20.6s,\testimator xgboost's best error=0.3516,\tbest estimator xgboost's best error=0.3516\n",
      "[flaml.automl.logger: 08-28 12:26:22] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:27:05] {2391} INFO -  at 64.0s,\testimator xgboost's best error=0.3233,\tbest estimator xgboost's best error=0.3233\n",
      "[flaml.automl.logger: 08-28 12:27:05] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:28:56] {2391} INFO -  at 174.5s,\testimator xgboost's best error=0.3007,\tbest estimator xgboost's best error=0.3007\n",
      "[flaml.automl.logger: 08-28 12:29:18] {2627} INFO - retrain xgboost for 22.1s\n",
      "[flaml.automl.logger: 08-28 12:29:18] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=105,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1122, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:29:18] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:29:18] {1931} INFO - Time taken to find the best model: 174.5161418914795\n",
      "Testing r2 = 0.5905563254274859\n",
      "Training r2 = 0.9691769840446917\n",
      "[flaml.automl.logger: 08-28 12:29:25] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:29:25] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:29:25] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:29:25] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2344} INFO - Estimated sufficient time budget=1744s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2391} INFO -  at 0.2s,\testimator xgboost's best error=10.0092,\tbest estimator xgboost's best error=10.0092\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2391} INFO -  at 0.4s,\testimator xgboost's best error=10.0092,\tbest estimator xgboost's best error=10.0092\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2391} INFO -  at 0.6s,\testimator xgboost's best error=6.7111,\tbest estimator xgboost's best error=6.7111\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.7111,\tbest estimator xgboost's best error=6.7111\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2391} INFO -  at 1.1s,\testimator xgboost's best error=0.6386,\tbest estimator xgboost's best error=0.6386\n",
      "[flaml.automl.logger: 08-28 12:29:26] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:27] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.6386,\tbest estimator xgboost's best error=0.6386\n",
      "[flaml.automl.logger: 08-28 12:29:27] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:27] {2391} INFO -  at 1.8s,\testimator xgboost's best error=0.5211,\tbest estimator xgboost's best error=0.5211\n",
      "[flaml.automl.logger: 08-28 12:29:27] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:28] {2391} INFO -  at 2.8s,\testimator xgboost's best error=0.5127,\tbest estimator xgboost's best error=0.5127\n",
      "[flaml.automl.logger: 08-28 12:29:28] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:29] {2391} INFO -  at 3.4s,\testimator xgboost's best error=0.5127,\tbest estimator xgboost's best error=0.5127\n",
      "[flaml.automl.logger: 08-28 12:29:29] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:30] {2391} INFO -  at 4.1s,\testimator xgboost's best error=0.5127,\tbest estimator xgboost's best error=0.5127\n",
      "[flaml.automl.logger: 08-28 12:29:30] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:31] {2391} INFO -  at 5.8s,\testimator xgboost's best error=0.5127,\tbest estimator xgboost's best error=0.5127\n",
      "[flaml.automl.logger: 08-28 12:29:31] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:32] {2391} INFO -  at 6.3s,\testimator xgboost's best error=0.5127,\tbest estimator xgboost's best error=0.5127\n",
      "[flaml.automl.logger: 08-28 12:29:32] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:35] {2391} INFO -  at 9.2s,\testimator xgboost's best error=0.3890,\tbest estimator xgboost's best error=0.3890\n",
      "[flaml.automl.logger: 08-28 12:29:35] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:36] {2391} INFO -  at 10.3s,\testimator xgboost's best error=0.3890,\tbest estimator xgboost's best error=0.3890\n",
      "[flaml.automl.logger: 08-28 12:29:36] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:44] {2391} INFO -  at 18.7s,\testimator xgboost's best error=0.3332,\tbest estimator xgboost's best error=0.3332\n",
      "[flaml.automl.logger: 08-28 12:29:44] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:29:46] {2391} INFO -  at 20.7s,\testimator xgboost's best error=0.3332,\tbest estimator xgboost's best error=0.3332\n",
      "[flaml.automl.logger: 08-28 12:29:46] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:30:30] {2391} INFO -  at 64.9s,\testimator xgboost's best error=0.3028,\tbest estimator xgboost's best error=0.3028\n",
      "[flaml.automl.logger: 08-28 12:30:30] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:26] {2391} INFO -  at 180.3s,\testimator xgboost's best error=0.2830,\tbest estimator xgboost's best error=0.2830\n",
      "[flaml.automl.logger: 08-28 12:32:49] {2627} INFO - retrain xgboost for 23.7s\n",
      "[flaml.automl.logger: 08-28 12:32:49] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=106,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1162, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:32:49] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:32:49] {1931} INFO - Time taken to find the best model: 180.2869713306427\n",
      "Testing r2 = 0.6108770637107064\n",
      "Training r2 = 0.9672935472877959\n",
      "[flaml.automl.logger: 08-28 12:32:58] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:32:58] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:32:58] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:32:58] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2344} INFO - Estimated sufficient time budget=1795s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2391} INFO -  at 0.3s,\testimator xgboost's best error=10.0099,\tbest estimator xgboost's best error=10.0099\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2391} INFO -  at 0.4s,\testimator xgboost's best error=10.0099,\tbest estimator xgboost's best error=10.0099\n",
      "[flaml.automl.logger: 08-28 12:32:58] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2391} INFO -  at 0.6s,\testimator xgboost's best error=6.7072,\tbest estimator xgboost's best error=6.7072\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.7072,\tbest estimator xgboost's best error=6.7072\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2391} INFO -  at 1.1s,\testimator xgboost's best error=0.6408,\tbest estimator xgboost's best error=0.6408\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2391} INFO -  at 1.3s,\testimator xgboost's best error=0.6408,\tbest estimator xgboost's best error=0.6408\n",
      "[flaml.automl.logger: 08-28 12:32:59] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:00] {2391} INFO -  at 1.8s,\testimator xgboost's best error=0.5187,\tbest estimator xgboost's best error=0.5187\n",
      "[flaml.automl.logger: 08-28 12:33:00] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:01] {2391} INFO -  at 2.9s,\testimator xgboost's best error=0.5041,\tbest estimator xgboost's best error=0.5041\n",
      "[flaml.automl.logger: 08-28 12:33:01] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:02] {2391} INFO -  at 3.7s,\testimator xgboost's best error=0.5041,\tbest estimator xgboost's best error=0.5041\n",
      "[flaml.automl.logger: 08-28 12:33:02] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:02] {2391} INFO -  at 4.4s,\testimator xgboost's best error=0.5041,\tbest estimator xgboost's best error=0.5041\n",
      "[flaml.automl.logger: 08-28 12:33:02] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:04] {2391} INFO -  at 6.1s,\testimator xgboost's best error=0.5041,\tbest estimator xgboost's best error=0.5041\n",
      "[flaml.automl.logger: 08-28 12:33:04] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:05] {2391} INFO -  at 6.6s,\testimator xgboost's best error=0.5041,\tbest estimator xgboost's best error=0.5041\n",
      "[flaml.automl.logger: 08-28 12:33:05] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:08] {2391} INFO -  at 9.6s,\testimator xgboost's best error=0.3828,\tbest estimator xgboost's best error=0.3828\n",
      "[flaml.automl.logger: 08-28 12:33:08] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:09] {2391} INFO -  at 10.8s,\testimator xgboost's best error=0.3828,\tbest estimator xgboost's best error=0.3828\n",
      "[flaml.automl.logger: 08-28 12:33:09] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:17] {2391} INFO -  at 19.5s,\testimator xgboost's best error=0.3263,\tbest estimator xgboost's best error=0.3263\n",
      "[flaml.automl.logger: 08-28 12:33:17] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:33:20] {2391} INFO -  at 21.6s,\testimator xgboost's best error=0.3263,\tbest estimator xgboost's best error=0.3263\n",
      "[flaml.automl.logger: 08-28 12:33:20] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:34:07] {2391} INFO -  at 69.5s,\testimator xgboost's best error=0.2914,\tbest estimator xgboost's best error=0.2914\n",
      "[flaml.automl.logger: 08-28 12:34:07] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:35:59] {2391} INFO -  at 180.8s,\testimator xgboost's best error=0.2694,\tbest estimator xgboost's best error=0.2694\n",
      "[flaml.automl.logger: 08-28 12:36:26] {2627} INFO - retrain xgboost for 27.0s\n",
      "[flaml.automl.logger: 08-28 12:36:26] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=107,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1258, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:36:26] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:36:26] {1931} INFO - Time taken to find the best model: 180.80884099006653\n",
      "Testing r2 = 0.628870645361975\n",
      "Training r2 = 0.9685808115044452\n",
      "[flaml.automl.logger: 08-28 12:36:35] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:36:35] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:36:35] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:36:35] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:36:35] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2344} INFO - Estimated sufficient time budget=1811s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2391} INFO -  at 0.3s,\testimator xgboost's best error=9.9951,\tbest estimator xgboost's best error=9.9951\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2391} INFO -  at 0.5s,\testimator xgboost's best error=9.9951,\tbest estimator xgboost's best error=9.9951\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2391} INFO -  at 0.7s,\testimator xgboost's best error=6.6974,\tbest estimator xgboost's best error=6.6974\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2391} INFO -  at 0.9s,\testimator xgboost's best error=6.6974,\tbest estimator xgboost's best error=6.6974\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2391} INFO -  at 1.1s,\testimator xgboost's best error=0.6401,\tbest estimator xgboost's best error=0.6401\n",
      "[flaml.automl.logger: 08-28 12:36:36] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:37] {2391} INFO -  at 1.3s,\testimator xgboost's best error=0.6401,\tbest estimator xgboost's best error=0.6401\n",
      "[flaml.automl.logger: 08-28 12:36:37] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:37] {2391} INFO -  at 1.9s,\testimator xgboost's best error=0.5116,\tbest estimator xgboost's best error=0.5116\n",
      "[flaml.automl.logger: 08-28 12:36:37] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:38] {2391} INFO -  at 3.0s,\testimator xgboost's best error=0.5015,\tbest estimator xgboost's best error=0.5015\n",
      "[flaml.automl.logger: 08-28 12:36:38] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:39] {2391} INFO -  at 3.6s,\testimator xgboost's best error=0.5015,\tbest estimator xgboost's best error=0.5015\n",
      "[flaml.automl.logger: 08-28 12:36:39] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:40] {2391} INFO -  at 4.5s,\testimator xgboost's best error=0.5015,\tbest estimator xgboost's best error=0.5015\n",
      "[flaml.automl.logger: 08-28 12:36:40] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:42] {2391} INFO -  at 6.2s,\testimator xgboost's best error=0.5015,\tbest estimator xgboost's best error=0.5015\n",
      "[flaml.automl.logger: 08-28 12:36:42] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:42] {2391} INFO -  at 6.8s,\testimator xgboost's best error=0.5015,\tbest estimator xgboost's best error=0.5015\n",
      "[flaml.automl.logger: 08-28 12:36:42] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:45] {2391} INFO -  at 10.1s,\testimator xgboost's best error=0.3721,\tbest estimator xgboost's best error=0.3721\n",
      "[flaml.automl.logger: 08-28 12:36:45] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:47] {2391} INFO -  at 11.3s,\testimator xgboost's best error=0.3721,\tbest estimator xgboost's best error=0.3721\n",
      "[flaml.automl.logger: 08-28 12:36:47] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:56] {2391} INFO -  at 20.8s,\testimator xgboost's best error=0.3164,\tbest estimator xgboost's best error=0.3164\n",
      "[flaml.automl.logger: 08-28 12:36:56] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:36:58] {2391} INFO -  at 23.0s,\testimator xgboost's best error=0.3164,\tbest estimator xgboost's best error=0.3164\n",
      "[flaml.automl.logger: 08-28 12:36:58] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:37:51] {2391} INFO -  at 75.5s,\testimator xgboost's best error=0.2833,\tbest estimator xgboost's best error=0.2833\n",
      "[flaml.automl.logger: 08-28 12:37:51] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:39:36] {2391} INFO -  at 180.7s,\testimator xgboost's best error=0.2667,\tbest estimator xgboost's best error=0.2667\n",
      "[flaml.automl.logger: 08-28 12:40:04] {2627} INFO - retrain xgboost for 27.8s\n",
      "[flaml.automl.logger: 08-28 12:40:04] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=113,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1323, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:40:04] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:40:04] {1931} INFO - Time taken to find the best model: 180.73791885375977\n",
      "Testing r2 = 0.644216614980868\n",
      "Training r2 = 0.9686719015429958\n",
      "[flaml.automl.logger: 08-28 12:40:15] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:40:15] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:40:15] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:40:15] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2344} INFO - Estimated sufficient time budget=1845s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2391} INFO -  at 0.3s,\testimator xgboost's best error=10.0084,\tbest estimator xgboost's best error=10.0084\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2391} INFO -  at 0.5s,\testimator xgboost's best error=10.0084,\tbest estimator xgboost's best error=10.0084\n",
      "[flaml.automl.logger: 08-28 12:40:15] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2391} INFO -  at 0.7s,\testimator xgboost's best error=6.7083,\tbest estimator xgboost's best error=6.7083\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2391} INFO -  at 0.9s,\testimator xgboost's best error=6.7083,\tbest estimator xgboost's best error=6.7083\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2391} INFO -  at 1.1s,\testimator xgboost's best error=0.6436,\tbest estimator xgboost's best error=0.6436\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2391} INFO -  at 1.3s,\testimator xgboost's best error=0.6436,\tbest estimator xgboost's best error=0.6436\n",
      "[flaml.automl.logger: 08-28 12:40:16] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:17] {2391} INFO -  at 1.9s,\testimator xgboost's best error=0.5048,\tbest estimator xgboost's best error=0.5048\n",
      "[flaml.automl.logger: 08-28 12:40:17] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:18] {2391} INFO -  at 3.1s,\testimator xgboost's best error=0.4971,\tbest estimator xgboost's best error=0.4971\n",
      "[flaml.automl.logger: 08-28 12:40:18] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:19] {2391} INFO -  at 3.7s,\testimator xgboost's best error=0.4971,\tbest estimator xgboost's best error=0.4971\n",
      "[flaml.automl.logger: 08-28 12:40:19] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:19] {2391} INFO -  at 4.5s,\testimator xgboost's best error=0.4971,\tbest estimator xgboost's best error=0.4971\n",
      "[flaml.automl.logger: 08-28 12:40:19] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:21] {2391} INFO -  at 6.2s,\testimator xgboost's best error=0.4971,\tbest estimator xgboost's best error=0.4971\n",
      "[flaml.automl.logger: 08-28 12:40:21] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:22] {2391} INFO -  at 6.7s,\testimator xgboost's best error=0.4971,\tbest estimator xgboost's best error=0.4971\n",
      "[flaml.automl.logger: 08-28 12:40:22] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:25] {2391} INFO -  at 10.0s,\testimator xgboost's best error=0.3720,\tbest estimator xgboost's best error=0.3720\n",
      "[flaml.automl.logger: 08-28 12:40:25] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:26] {2391} INFO -  at 11.3s,\testimator xgboost's best error=0.3720,\tbest estimator xgboost's best error=0.3720\n",
      "[flaml.automl.logger: 08-28 12:40:26] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:36] {2391} INFO -  at 21.1s,\testimator xgboost's best error=0.3084,\tbest estimator xgboost's best error=0.3084\n",
      "[flaml.automl.logger: 08-28 12:40:36] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:40:38] {2391} INFO -  at 23.3s,\testimator xgboost's best error=0.3084,\tbest estimator xgboost's best error=0.3084\n",
      "[flaml.automl.logger: 08-28 12:40:38] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:41:34] {2391} INFO -  at 79.4s,\testimator xgboost's best error=0.2671,\tbest estimator xgboost's best error=0.2671\n",
      "[flaml.automl.logger: 08-28 12:41:34] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:16] {2391} INFO -  at 180.7s,\testimator xgboost's best error=0.2508,\tbest estimator xgboost's best error=0.2508\n",
      "[flaml.automl.logger: 08-28 12:43:46] {2627} INFO - retrain xgboost for 30.2s\n",
      "[flaml.automl.logger: 08-28 12:43:46] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=114,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1363, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:43:46] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:43:46] {1931} INFO - Time taken to find the best model: 180.71550869941711\n",
      "Testing r2 = 0.6442956418379706\n",
      "Training r2 = 0.9677935512250488\n",
      "[flaml.automl.logger: 08-28 12:43:58] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:43:58] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:43:58] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:43:58] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2344} INFO - Estimated sufficient time budget=1910s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2391} INFO -  at 0.3s,\testimator xgboost's best error=10.0141,\tbest estimator xgboost's best error=10.0141\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2391} INFO -  at 0.5s,\testimator xgboost's best error=10.0141,\tbest estimator xgboost's best error=10.0141\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2391} INFO -  at 0.7s,\testimator xgboost's best error=6.7103,\tbest estimator xgboost's best error=6.7103\n",
      "[flaml.automl.logger: 08-28 12:43:58] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2391} INFO -  at 0.9s,\testimator xgboost's best error=6.7103,\tbest estimator xgboost's best error=6.7103\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.6389,\tbest estimator xgboost's best error=0.6389\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2391} INFO -  at 1.4s,\testimator xgboost's best error=0.6389,\tbest estimator xgboost's best error=0.6389\n",
      "[flaml.automl.logger: 08-28 12:43:59] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:00] {2391} INFO -  at 2.0s,\testimator xgboost's best error=0.4970,\tbest estimator xgboost's best error=0.4970\n",
      "[flaml.automl.logger: 08-28 12:44:00] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:01] {2391} INFO -  at 3.3s,\testimator xgboost's best error=0.4852,\tbest estimator xgboost's best error=0.4852\n",
      "[flaml.automl.logger: 08-28 12:44:01] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:02] {2391} INFO -  at 3.9s,\testimator xgboost's best error=0.4852,\tbest estimator xgboost's best error=0.4852\n",
      "[flaml.automl.logger: 08-28 12:44:02] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:02] {2391} INFO -  at 4.8s,\testimator xgboost's best error=0.4852,\tbest estimator xgboost's best error=0.4852\n",
      "[flaml.automl.logger: 08-28 12:44:02] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:04] {2391} INFO -  at 6.8s,\testimator xgboost's best error=0.4852,\tbest estimator xgboost's best error=0.4852\n",
      "[flaml.automl.logger: 08-28 12:44:04] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:05] {2391} INFO -  at 7.3s,\testimator xgboost's best error=0.4852,\tbest estimator xgboost's best error=0.4852\n",
      "[flaml.automl.logger: 08-28 12:44:05] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:09] {2391} INFO -  at 11.0s,\testimator xgboost's best error=0.3521,\tbest estimator xgboost's best error=0.3521\n",
      "[flaml.automl.logger: 08-28 12:44:09] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:10] {2391} INFO -  at 12.4s,\testimator xgboost's best error=0.3521,\tbest estimator xgboost's best error=0.3521\n",
      "[flaml.automl.logger: 08-28 12:44:10] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:22] {2391} INFO -  at 24.2s,\testimator xgboost's best error=0.2959,\tbest estimator xgboost's best error=0.2959\n",
      "[flaml.automl.logger: 08-28 12:44:22] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:44:24] {2391} INFO -  at 26.7s,\testimator xgboost's best error=0.2959,\tbest estimator xgboost's best error=0.2959\n",
      "[flaml.automl.logger: 08-28 12:44:24] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:45:32] {2391} INFO -  at 94.3s,\testimator xgboost's best error=0.2569,\tbest estimator xgboost's best error=0.2569\n",
      "[flaml.automl.logger: 08-28 12:45:32] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:46:58] {2391} INFO -  at 180.6s,\testimator xgboost's best error=0.2446,\tbest estimator xgboost's best error=0.2446\n",
      "[flaml.automl.logger: 08-28 12:47:31] {2627} INFO - retrain xgboost for 32.4s\n",
      "[flaml.automl.logger: 08-28 12:47:31] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=115,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1494, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:47:31] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:47:31] {1931} INFO - Time taken to find the best model: 180.58960556983948\n",
      "Testing r2 = 0.6618873478724068\n",
      "Training r2 = 0.9691331863030133\n",
      "[flaml.automl.logger: 08-28 12:47:44] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:47:44] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:47:44] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:47:44] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:47:44] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2344} INFO - Estimated sufficient time budget=2005s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2391} INFO -  at 0.3s,\testimator xgboost's best error=9.9962,\tbest estimator xgboost's best error=9.9962\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2391} INFO -  at 0.5s,\testimator xgboost's best error=9.9962,\tbest estimator xgboost's best error=9.9962\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.6970,\tbest estimator xgboost's best error=6.6970\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2391} INFO -  at 1.0s,\testimator xgboost's best error=6.6970,\tbest estimator xgboost's best error=6.6970\n",
      "[flaml.automl.logger: 08-28 12:47:45] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:46] {2391} INFO -  at 1.3s,\testimator xgboost's best error=0.6377,\tbest estimator xgboost's best error=0.6377\n",
      "[flaml.automl.logger: 08-28 12:47:46] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:46] {2391} INFO -  at 1.5s,\testimator xgboost's best error=0.6377,\tbest estimator xgboost's best error=0.6377\n",
      "[flaml.automl.logger: 08-28 12:47:46] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:47] {2391} INFO -  at 2.2s,\testimator xgboost's best error=0.4978,\tbest estimator xgboost's best error=0.4978\n",
      "[flaml.automl.logger: 08-28 12:47:47] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:48] {2391} INFO -  at 3.5s,\testimator xgboost's best error=0.4860,\tbest estimator xgboost's best error=0.4860\n",
      "[flaml.automl.logger: 08-28 12:47:48] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:49] {2391} INFO -  at 4.2s,\testimator xgboost's best error=0.4860,\tbest estimator xgboost's best error=0.4860\n",
      "[flaml.automl.logger: 08-28 12:47:49] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:49] {2391} INFO -  at 5.1s,\testimator xgboost's best error=0.4860,\tbest estimator xgboost's best error=0.4860\n",
      "[flaml.automl.logger: 08-28 12:47:49] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:52] {2391} INFO -  at 7.1s,\testimator xgboost's best error=0.4860,\tbest estimator xgboost's best error=0.4860\n",
      "[flaml.automl.logger: 08-28 12:47:52] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:52] {2391} INFO -  at 7.7s,\testimator xgboost's best error=0.4860,\tbest estimator xgboost's best error=0.4860\n",
      "[flaml.automl.logger: 08-28 12:47:52] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:56] {2391} INFO -  at 11.5s,\testimator xgboost's best error=0.3418,\tbest estimator xgboost's best error=0.3418\n",
      "[flaml.automl.logger: 08-28 12:47:56] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:47:57] {2391} INFO -  at 12.9s,\testimator xgboost's best error=0.3418,\tbest estimator xgboost's best error=0.3418\n",
      "[flaml.automl.logger: 08-28 12:47:57] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:48:08] {2391} INFO -  at 24.0s,\testimator xgboost's best error=0.2863,\tbest estimator xgboost's best error=0.2863\n",
      "[flaml.automl.logger: 08-28 12:48:08] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:48:11] {2391} INFO -  at 26.7s,\testimator xgboost's best error=0.2863,\tbest estimator xgboost's best error=0.2863\n",
      "[flaml.automl.logger: 08-28 12:48:11] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:49:14] {2391} INFO -  at 89.9s,\testimator xgboost's best error=0.2502,\tbest estimator xgboost's best error=0.2502\n",
      "[flaml.automl.logger: 08-28 12:49:14] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:50:45] {2391} INFO -  at 180.6s,\testimator xgboost's best error=0.2353,\tbest estimator xgboost's best error=0.2353\n",
      "[flaml.automl.logger: 08-28 12:51:20] {2627} INFO - retrain xgboost for 34.6s\n",
      "[flaml.automl.logger: 08-28 12:51:20] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=116,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1561, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:51:20] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:51:20] {1931} INFO - Time taken to find the best model: 180.63824248313904\n",
      "Testing r2 = 0.6751945271039135\n",
      "Training r2 = 0.970029870835838\n",
      "[flaml.automl.logger: 08-28 12:51:35] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:51:35] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:51:35] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:51:35] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2344} INFO - Estimated sufficient time budget=2016s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2391} INFO -  at 0.3s,\testimator xgboost's best error=10.0299,\tbest estimator xgboost's best error=10.0299\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2391} INFO -  at 0.5s,\testimator xgboost's best error=10.0299,\tbest estimator xgboost's best error=10.0299\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2391} INFO -  at 0.7s,\testimator xgboost's best error=6.7202,\tbest estimator xgboost's best error=6.7202\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2391} INFO -  at 1.0s,\testimator xgboost's best error=6.7202,\tbest estimator xgboost's best error=6.7202\n",
      "[flaml.automl.logger: 08-28 12:51:35] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:36] {2391} INFO -  at 1.2s,\testimator xgboost's best error=0.6414,\tbest estimator xgboost's best error=0.6414\n",
      "[flaml.automl.logger: 08-28 12:51:36] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:36] {2391} INFO -  at 1.5s,\testimator xgboost's best error=0.6414,\tbest estimator xgboost's best error=0.6414\n",
      "[flaml.automl.logger: 08-28 12:51:36] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:37] {2391} INFO -  at 2.2s,\testimator xgboost's best error=0.4906,\tbest estimator xgboost's best error=0.4906\n",
      "[flaml.automl.logger: 08-28 12:51:37] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:38] {2391} INFO -  at 3.5s,\testimator xgboost's best error=0.4829,\tbest estimator xgboost's best error=0.4829\n",
      "[flaml.automl.logger: 08-28 12:51:38] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:39] {2391} INFO -  at 4.1s,\testimator xgboost's best error=0.4829,\tbest estimator xgboost's best error=0.4829\n",
      "[flaml.automl.logger: 08-28 12:51:39] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:40] {2391} INFO -  at 5.0s,\testimator xgboost's best error=0.4829,\tbest estimator xgboost's best error=0.4829\n",
      "[flaml.automl.logger: 08-28 12:51:40] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:42] {2391} INFO -  at 7.0s,\testimator xgboost's best error=0.4829,\tbest estimator xgboost's best error=0.4829\n",
      "[flaml.automl.logger: 08-28 12:51:42] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:42] {2391} INFO -  at 7.6s,\testimator xgboost's best error=0.4829,\tbest estimator xgboost's best error=0.4829\n",
      "[flaml.automl.logger: 08-28 12:51:42] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:46] {2391} INFO -  at 11.3s,\testimator xgboost's best error=0.3376,\tbest estimator xgboost's best error=0.3376\n",
      "[flaml.automl.logger: 08-28 12:51:46] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:47] {2391} INFO -  at 12.6s,\testimator xgboost's best error=0.3376,\tbest estimator xgboost's best error=0.3376\n",
      "[flaml.automl.logger: 08-28 12:51:47] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:51:58] {2391} INFO -  at 23.8s,\testimator xgboost's best error=0.2827,\tbest estimator xgboost's best error=0.2827\n",
      "[flaml.automl.logger: 08-28 12:51:58] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:52:01] {2391} INFO -  at 26.4s,\testimator xgboost's best error=0.2827,\tbest estimator xgboost's best error=0.2827\n",
      "[flaml.automl.logger: 08-28 12:52:01] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:53:06] {2391} INFO -  at 91.1s,\testimator xgboost's best error=0.2417,\tbest estimator xgboost's best error=0.2417\n",
      "[flaml.automl.logger: 08-28 12:53:06] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:54:35] {2391} INFO -  at 180.6s,\testimator xgboost's best error=0.2281,\tbest estimator xgboost's best error=0.2281\n",
      "[flaml.automl.logger: 08-28 12:55:11] {2627} INFO - retrain xgboost for 36.2s\n",
      "[flaml.automl.logger: 08-28 12:55:11] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=117,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1594, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:55:11] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:55:11] {1931} INFO - Time taken to find the best model: 180.62393069267273\n",
      "Testing r2 = 0.6920589312787173\n",
      "Training r2 = 0.9673511104130365\n",
      "[flaml.automl.logger: 08-28 12:55:27] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 08-28 12:55:27] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-28 12:55:27] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 08-28 12:55:27] {1900} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 08-28 12:55:27] {2218} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:27] {2344} INFO - Estimated sufficient time budget=2304s. Estimated necessary time budget=2s.\n",
      "[flaml.automl.logger: 08-28 12:55:27] {2391} INFO -  at 0.3s,\testimator xgboost's best error=10.0587,\tbest estimator xgboost's best error=10.0587\n",
      "[flaml.automl.logger: 08-28 12:55:27] {2218} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2391} INFO -  at 0.6s,\testimator xgboost's best error=10.0587,\tbest estimator xgboost's best error=10.0587\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2391} INFO -  at 0.8s,\testimator xgboost's best error=6.7398,\tbest estimator xgboost's best error=6.7398\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2391} INFO -  at 1.1s,\testimator xgboost's best error=6.7398,\tbest estimator xgboost's best error=6.7398\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2391} INFO -  at 1.4s,\testimator xgboost's best error=0.6341,\tbest estimator xgboost's best error=0.6341\n",
      "[flaml.automl.logger: 08-28 12:55:28] {2218} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:29] {2391} INFO -  at 1.6s,\testimator xgboost's best error=0.6341,\tbest estimator xgboost's best error=0.6341\n",
      "[flaml.automl.logger: 08-28 12:55:29] {2218} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:29] {2391} INFO -  at 2.3s,\testimator xgboost's best error=0.4954,\tbest estimator xgboost's best error=0.4954\n",
      "[flaml.automl.logger: 08-28 12:55:29] {2218} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:31] {2391} INFO -  at 3.7s,\testimator xgboost's best error=0.4807,\tbest estimator xgboost's best error=0.4807\n",
      "[flaml.automl.logger: 08-28 12:55:31] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:31] {2391} INFO -  at 4.4s,\testimator xgboost's best error=0.4807,\tbest estimator xgboost's best error=0.4807\n",
      "[flaml.automl.logger: 08-28 12:55:31] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:32] {2391} INFO -  at 5.2s,\testimator xgboost's best error=0.4807,\tbest estimator xgboost's best error=0.4807\n",
      "[flaml.automl.logger: 08-28 12:55:32] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:35] {2391} INFO -  at 7.5s,\testimator xgboost's best error=0.4807,\tbest estimator xgboost's best error=0.4807\n",
      "[flaml.automl.logger: 08-28 12:55:35] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:35] {2391} INFO -  at 8.1s,\testimator xgboost's best error=0.4807,\tbest estimator xgboost's best error=0.4807\n",
      "[flaml.automl.logger: 08-28 12:55:35] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:39] {2391} INFO -  at 12.2s,\testimator xgboost's best error=0.3269,\tbest estimator xgboost's best error=0.3269\n",
      "[flaml.automl.logger: 08-28 12:55:39] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:41] {2391} INFO -  at 13.6s,\testimator xgboost's best error=0.3269,\tbest estimator xgboost's best error=0.3269\n",
      "[flaml.automl.logger: 08-28 12:55:41] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:52] {2391} INFO -  at 25.0s,\testimator xgboost's best error=0.2703,\tbest estimator xgboost's best error=0.2703\n",
      "[flaml.automl.logger: 08-28 12:55:52] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:55:55] {2391} INFO -  at 27.8s,\testimator xgboost's best error=0.2703,\tbest estimator xgboost's best error=0.2703\n",
      "[flaml.automl.logger: 08-28 12:55:55] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:57:00] {2391} INFO -  at 93.3s,\testimator xgboost's best error=0.2258,\tbest estimator xgboost's best error=0.2258\n",
      "[flaml.automl.logger: 08-28 12:57:00] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 08-28 12:58:28] {2391} INFO -  at 180.6s,\testimator xgboost's best error=0.2162,\tbest estimator xgboost's best error=0.2162\n",
      "[flaml.automl.logger: 08-28 12:59:05] {2627} INFO - retrain xgboost for 37.2s\n",
      "[flaml.automl.logger: 08-28 12:59:05] {2630} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.969129617566699, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy='lossguide',\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.091294396880665, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=0, max_leaves=118,\n",
      "             min_child_weight=0.2811326929960469, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1633, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 08-28 12:59:05] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-28 12:59:05] {1931} INFO - Time taken to find the best model: 180.60962390899658\n",
      "Testing r2 = 0.7163311205703493\n",
      "Training r2 = 0.9681760824680304\n"
     ]
    }
   ],
   "source": [
    "test_bias, train_bias = bias_variance_tradeoff_params(x,y,best_hyperparams,train_split_percentages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient of Determination vs training %**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAAKKCAYAAAAEB3X4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABcSAAAXEgFnn9JSAACFkklEQVR4nO3dd3wUZeLH8e+mV9ITeoAAAZFQBJTe7KAiIOpZUM52p2cveKcn9rOhnv2nHuhZQBGxHYjSkY50pYUWFEgCBNLr8/sj7JoluyFlUyZ83q9XXoSZ2Zlnn8zMznef55mxGWOMAAAAAMCivOq7AAAAAABQE4QaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqIGmTJmivn37qkmTJrLZbLLZbHrllVcc84uLizV58mT16NFDwcHBjmVmzZolSRoyZIhsNpsmTZrksTLZt7Fw4UKPrbMxOdXfBA3T1KlTZbPZ1KZNm/ouSrVMmjRJNptNQ4YMqe+iVIlVy93Y7dmzx3Hu2rNnT30XB1VUm8fVDTfcIJvNphtuuMHj627MKjqmTofjjVDjIcXFxfrss890/fXXq2PHjgoPD5efn59iY2M1YMAAPfzww9q8eXN9F7Ocl156SRMmTNCKFSuUm5ur2NhYxcXFKTg42LHM3Xffrfvuu0/r169XUVGR4uLiFBcXp4CAgHosef2YOnWqJk2aVO9hq6Z/E/sHRtkfb29vhYWFqXXr1hoyZIjuuecezZ49WyUlJbX6XiZNmqRJkyY12pOsFaxfv16TJk1y+jID7o0aNUo2m03vv/9+nW/75OO2Kj9Tp06ts3KeTsf1/v379be//U3t27eXv7+/IiIi1LVrV916662aM2dOtde7cOHCGv29T4e6b6iysrL06quvatiwYYqLi5Ofn58iIyPVuXNnXXDBBXr88cc1f/58FRcX13dRJZUGHvsxa2U+9V2AxmDFihUaP368tm/f7pjm6+ur0NBQHT58WD/99JN++ukn/etf/9Lo0aP16aefys/Prx5L/IcXX3xRknTnnXfqxRdflK+vr9P8zMxMvfPOO5Kk559/Xvfff79sNpvTMq1bt1ZiYqKio6M9Vq7ExERJUlBQkMfW6QlTp07VokWLJKnevvWtzN+ksry8vBQTE+P4f3Z2tlJSUpSSkqJFixbplVdeUatWrfTyyy9rzJgxHin/yR5//HFJpfVp1RaMygoLC1NiYqJatGhR30Vxsn79ej3++OOKj4/X3Xff7Xa56OhoJSYmqnXr1nVXuAYmNzdXP/zwg7y8vDRy5Mg6335cXJzL6VlZWcrOzq5wmcDAwFor18kqc1z7+vo6zvUnf/ZYxbp16zR8+HAdPXpUkuTjU3pZtXnzZm3evFn/93//J2NMtdbt5+fn9m955MgRFRYWytfXV5GRkS6X8fb2rtZ2K6s2zwfNmjVTYmKimjVr5vF117aNGzdq5MiRSklJcUwLCAiQMUbbtm3T1q1bNXfuXEnS7t276+xzr6Ljbc+ePY5j1tLBxqBGvv76a+Pv728kmaioKPPss8+a7du3O+YXFRWZ1atXm4kTJ5omTZoYSebo0aP1V+AyUlNTjSQjyWzatMnlMqtWrXIsk5mZWcclbHgGDx5sJJnHHnus3srgib/J+PHjjSQTHx9fbl5+fr5ZvXq1mTRpkomLi3Ns6+GHH65hyV2zr3/BggW1sn6c2pQpU9zuD43BY489ZiSZwYMH13hdX331lZFk+vXrV/OCeZD9PTaUj/XT5bg+66yzjCQTHh5uvvzyS1NUVGSMMSY9Pd28//77pn///rWyXftnkSf2aXjO8ePHTYsWLYwkEx0dbV599VWTmprqmJ+VlWUWL15sHnzwQdOsWTOze/duj25/9+7djmOvKutesGBBgzp/VBfdz2pgx44duvbaa5Wfn68zzjhD69ev18SJE9WhQwfHMt7e3urVq5eeffZZ7d69W5dddlk9lthZTk6O4/eQkJBqL4O6Vdt/Ez8/P/Xq1UuPPfaYtmzZoqFDh0qSnn32WX3yySce3x5gJV999ZUkNahzOerHkSNHtHbtWknSU089pVGjRjlaR6KiojRhwgQtXbq0PouIOjZt2jT99ttvkqRvvvlGd955p1NviODgYA0cOFDPPfec9u3bp5YtW9ZXURslQk0NPPLIIzp+/LgCAgL05ZdfnnLnjIyM1KxZsxQWFlZu3sGDB/XAAw+oS5cuCgkJUXBwsLp06aIHH3xQhw4dOmVZFi5cqKuvvlqtW7dWQECAwsLC1KdPHz3//POOLglllz15sHLbtm0d/XDbtGnjGNBctotV2b66ZadX5kYBv/76q26//XadccYZCg0NVUhIiBITE3XVVVfpiy++KDduozI3CqjKe7Y7efDhjBkzNGTIEEVGRiooKEjdu3fXq6++Wq489vqwdz17/PHHa9x/ubi4WP/5z380bNgwRUdHy9/fXy1atNAVV1zh8n1X5W/iKVFRUZo5c6aju9QjjzyiwsJCl8vm5eXp3//+twYPHqzo6Gj5+fmpadOmGjVqlMt+5fa/hd3QoUOd3o+7JvlZs2Zp1KhRat68ufz8/BQREaFBgwbp7bffdlu2svtoYWGhXnrpJfXq1Uvh4eFO+1mbNm0cYw9ycnI0adIkde7cWUFBQWrevLmuu+467d6927He9PR0PfTQQ+rYsaMCAwPVtGlT3XTTTW6P2YpuFHDyoNt58+ZpxIgRiomJUUBAgDp37qzHH39ceXl5Ltedm5urr7/+WjfffLO6d++umJgY+fv7q3nz5ho1apRmz57t8nU2m0033nijJGnv3r3l9uuyx3VlBgavW7dO119/veLj4xUQEKCIiAj169dPr7zyivLz8ytVL2vXrtW4cePUrFkz+fv7q127drr33nsdXXxq6rPPPtPgwYMVGRmp4OBgnXXWWXr99ddP2b+9pKRE3377raQ/Qs2MGTNks9kUExPjspvRBRdc4KhLV+Mqn332WdlsNg0aNMgD76xix44d09NPP62zzz5bERER8vf3V6tWrXT11VdrxYoVbl939OhR/fOf/1TPnj3VpEkTx7GdlJSk2267TfPmzXMsW5XjuqKBy2XHk0jSzp07NWHCBLVq1Ur+/v5q2bKlbr75ZscFpDubNm3SVVddpaZNmyogIEDt2rXT3/72N6WmppbbRlV5e3s7XtuQupSe/L7WrVuna665Ri1btpSvr6/T8Zuamqr//Oc/Gj16tDp37qywsDAFBgaqffv2uummm7Rlyxa326nofFDdz1p3ry+r7PncGKN3331XZ599tpo0aaLQ0FD17dtXH330UYV1VFhYqJdfflndu3dXcHCwIiMjNWTIEM2YMaPcNqpi/fr1kqTY2Fidc845FS7r4+Pj6K5od/IxsWPHDt1www1q2bKl/P391bp1a912222n3O9dcXe8tWnTxvHlpVR+3N7Jf4OVK1fqmmuuUdu2bRUQEKDg4GDFx8dr8ODBevLJJ7V///4ql81j6rupyKoOHjxovLy8jCTz5z//uUbrWrhwoQkPD3c0/QUFBZng4GDH/yMiIsySJUtcvrawsNDcdNNNjmUlmZCQEOPt7e34f2JiotmzZ4/jNT/99JOJi4sz0dHRjmWio6NNXFyciYuLM7169TLTpk0zcXFxJiIiwrGMfX5cXJy5/PLLHes7VZesf/3rX466kmQCAgJMaGioU5lP7pKnCrouVOc929m7XY0fP97cfvvtRpLx8vJyqn9J5vrrr3d6nb0+fH19jSQTHBzsVB9xcXFm3759bv7C5WVkZJghQ4Y4tuft7W3Cw8ONzWZzTLv//vtdlqEyf5NTqaj7mSsvvPCCY5vz5s0rN3/79u2mQ4cOjmVsNpsJCwtzqtO//OUvTq+58847nbq3RUREOL2fXr16OS2fmZlpRo4c6bTOJk2aONVZ3759zZEjR8qVz76PPvTQQ6Zfv35GkvHx8XHUpX0/i4+PN5LMK6+8YpKSkhz7a2BgoGMb9i4DycnJpm3bto5j1s/Pz7FMhw4dzLFjx8qVo6JuXmW7SD3//PPGZrMZm81Wbr8YOnSoo4uLq3XbfwIDA01QUJDTtPvuu6/c6+Li4hxdY728vMrt1y+88ILLMrry8ssvO5U1LCzMccxIMklJSeb333+vsF4+/vhjx2vCwsKczh1dunSpVpfLsuV+8MEHHftoRESE0/ovuOACk5eX53Y9S5YsMZJMp06dHNPS09Md73nDhg1OyxcUFDidy1999dVy6zz33HONJPPPf/6zyu/L1Xt097G+YsUKp+PN29vb6Txss9nMM888U+51KSkppnXr1o7lvLy8TEREhNP5tuz+UJXjuqKuMmW7w8yfP9+EhIQYSSY0NNT4+Pg45jVv3tzs37/f5XueOXOm0/4XEhJiAgICHMdx2WOmui666CIjyQwbNswUFxdXez1VVVH3s7J1N2PGDEcdNGnSxAQEBDi9xv5ZUPacWrZ+/f39zYwZM1yWoaLzQXU/a1293t17f+SRR8xll13mOJ/bz2P2H3fHVFZWlhk0aJDTsRAREeE4jidOnFjtruZ//etfjSTj6+trsrOzq/RaY5yPiWnTpjmO0ZCQEKfPocjISLN27doKX3/yMeVuXq9evdxeV8TFxZk777zTsezUqVOdzvH+/v7l6n3KlClVft+eQqippk8//dTxB/z222+rvZ59+/Y5DvIzzjjDLF261DFv8eLFJjEx0bEDuzpx33XXXY6d8M033zSHDx82xpR+mC5YsMD06NHDSDI9e/Ysd8KtTN/LyvSzrOjgf/PNNx2vv/TSS826desc8w4fPmzmzp1rrrzyynIXgPbXuAo1NXnP9hNlRESE8fPzM5MnT3ZsOz093Sksubp499SYmjFjxhhJxs/Pz/z73/92nPwOHDhgJkyY4CjDW2+9Ve61nuj7WtVQ88svv7j9oDh69Khp06aN44N98eLFjgvDjIwMM3nyZMcFySuvvFJu3RX9rcsaNWqUkWTat29vPvnkE3P8+HFjjDG5ubnmq6++Mu3atTOSzKhRo8q91v53CwkJMSEhIWbKlCkmJyfHGFP6d7fvQ/ZQEx4ebtq0aWPmzp1riouLTVFRkZk7d67ji4Bx48aZPn36mO7du5vly5cbY0r3v+nTpzuCxD/+8Y9y5ahMqAkPDzdeXl7m4YcfNmlpacYYY44dO2b++c9/Ourq/fffL/f6L7/80txyyy1mwYIFJj093TH9999/N48//rjjwuarr76qUrlcldHVRcw333zjKN9ll11mdu3aZYwpHaP14YcfOj6c+/XrVy6U2bcfFBRk/P39zU033eT4kiA7O9u8/vrrjvI/+uijFZaxonLbg/Ydd9zh6Od+7Ngx8+STTzo+qO+55x6367n//vuNVBqOy7IH4Jdfftlpuj0E2T/0L7vsMqf5+fn5jv2lpmNPKgo1u3fvdnzOjB071qxdu9YUFhYaY4w5dOiQefTRRx0Xsl9++aXTa//85z8bSaZNmzbmxx9/dPztioqKzJ49e8xbb71Vrj6MqdxxXdlQExERYS699FLz66+/GmNK62369OmOfeq6664rt+7k5GRH3fbs2dOsWbPGGGNMSUmJ+eGHH0x8fLzThVx17dy507Fv3nrrraakpKTa66qKyoaakJAQc/HFFzvqzhjjNO530qRJ5pFHHjHr1q0zWVlZxhhjiouLzebNm80111xjpNIv8X777bdy26lMqKnuZ21lQk1ERIQJCwszU6dOdZzPU1JSzCWXXOIIUWXfq92tt97qmP/cc885vihJS0szd955p+M8XJ3P+qlTpzre11VXXeX4bKmsssdEWFiYSUpKMitXrjTGlO6733//veNLhtatWzs+B129vrKhxpjKXVdkZ2c7jrlrr73W7Ny50zEvKyvLrFmzxjzwwAPmu+++q9J79iRCTTU98sgjjh3A1cFeWbfddpvj4Dxw4EC5+SkpKY4PxNtvv91p3qZNm4zNZjNBQUFm48aNLtd//Phx07JlS5cfVrUdao4cOeI4AK666qoqnezdfSDW9D2X/VbK3bcJ9oGfN910U7l5ngg1K1eudJThnXfecbmMPfRER0eb3Nxcp3n1EWpKSkocLRHXXHON0zz7hd6wYcMcF0onmzlzpuP9nLxMZS5+vv32WyPJNG3a1O23sikpKY5vxcuGZ2P++LtJMl9//bXb7dhDTWBgoNmxY0e5+e+//75jPXFxcU7hwe7RRx81kkxCQkK5eZUJNRXtX6NHjzaSzLnnnuv2Pbhjb20bPnx4lcrlqoyuLmLOOOMMI8kMGDDAZUvS119/7Xh/n3/+ucvtu7uIMcaYe++91xFqq6ps3bq6ADbmj3O6j4+P23O6vTVy2bJlTtPvvvtuI8lccsklTtMff/xxI5XeZMPPz8+Eh4c7fdGyaNEiI5W2Bp58nNfkPZ5s7NixFb53Y4yZPHmykWS6devmNL1z585Gkvnkk0+qVB5PhpqhQ4e6bAX597//7TheTz6v2MNYbGysywvLrVu3Om7yU91zaU5Ojrniiisc67B/btRFi01lQ02fPn1cHo+VNWLECCPJPPnkk+XmVSbUVPeztjKhRiptxTtZXl6ead68uZFknnrqKad5e/fudbTOunpPJ5e9qp/1eXl55swzz3S83s/PzwwdOtQ89NBD5rPPPjtlj46yx0RUVJQ5dOhQuWV++eUXx+fx888/7/b1ng419muX4OBgt5/19Y0xNdV0+PBhx+/ubqd4KsYYffbZZ5Kk2267TU2bNi23TMuWLXXbbbdJKh2AVtb7778vY4xGjBihrl27utxGaGioRo0aJUn6/vvvq1XO6poxY4YyMzPl6+uryZMnV7vfclmees+tWrXS9ddf73LepZdeKqn0toy1wf53bNmypW666SaXyzz55JOSSsds/PDDD7VSjqqw2WyKiIiQVDo41s4Yo//85z+SpPvuu69c/2C7UaNGqUmTJkpPT3cMrK2K9957T5J03XXXue273rJlS0e/YHd/9y5duuiSSy455fbGjBmj9u3bl5t+wQUXOH6/5ZZbFBUV5XaZ5ORkt2O7KuLv76/777/f5Tz7OI7q7JsjRoyQJC1fvtzjz0bYuHGjfvnlF0nSo48+6vJWspdccon69OkjSfr000/druuRRx5xOd3+3nfu3Ol0s4yq+uc//+ly+gMPPKDAwEAVFRXpiy++KDf/119/1Y4dOxQXF6ezzz7baZ59v1u8eLFT3S5YsECSNHLkSPXp00cZGRn6+eefy83v27dvrT3368iRI5o5c6YkaeLEiW6Xs58PN2zY4DQmLDw8XJJ04MCBWilfZfz973+Xl1f5yxX7PpGbm6sdO3Y4phtjHH/Dv/zlLy4/oxMTEzVu3Lgalevaa6/V559/rj59+mjVqlVq2rSp3nvvPV1zzTUqKioqt/wvv/ziGKdQV/X5wAMP1OjWzvbzRnVveFCbn7X9+/d3Ggti5+/v7zgPn7xu+xjeoKAg3XPPPS7X++ijj1arPPZtz58/X1deeaVsNpsKCgq0YMECPffccxo3bpxat26tM844o8Ixhna33XabYmNjy03v3Lmzxo4dK6n8dWFtsp8LCgoKnK6BGxJCTTWZat53vqzdu3c7LhDPPfdct8udd955kkqDVNlByvaTzOzZs9W0aVO3P1OmTJFUOgi4Li1btkySdNZZZ3nsXvOees+9e/d2+SEpSc2bN5fkfPHuSWvWrJFUeiHkrgydO3d2XLzbl69vrvb5X375xVFPN9xwg9u/R7NmzZSVlSWpevuh/e/+f//3fxX+3X/88ccKt9G/f/9Kbc9+8X2yss+M6N279ymXycjIqNT2yrLfLMSVU+2bhw4d0mOPPaa+ffsqKipKPj4+jouoM844Q1Lp3fM8NeDezr6P+vj4aPDgwW6Xs5/L3O3TkZGRLsOk9Md7l1Tt8rdq1crt+ps0aaKzzjrLbflmzZolqTScnXzcDh48WN7e3jp27JgjtOfl5Wn58uUKCQlRnz59HBdf8+fPd7zO/rurCzNPWb58uWMw9rBhw9weO126dHG8puzxY38Wz8SJE3XLLbdozpw5On78eK2V15WTQ6Rd2X2i7DGxa9cux7FX0f5Yk5urvP/++5o5c6bCw8M1c+ZM9e7dW/PmzVNMTIymTZumMWPGlLtotQ+gjo2NrbPnr1TmnLdhwwb99a9/VVJSkpo0aSIvLy/HeeOvf/2rJFV78Hdtfta62y8qWrf9S4VevXo5PWS8rISEBLVq1apaZZLk2Ad2796tV199VePGjVNCQoLji91ff/1V99xzj/r27VthOBg2bNgp523cuNHtDXI8LSEhQZ06dVJhYaHOPvtsPffcc1q/fn2DeYCoxMM3q63sgyaPHDnidHKtrNTUVMfvFd05pexd1VJTU9W2bVtJ0u+//y6p9KFr9gvGitTk283qOHjwoCQpPj7eY+v01HsODQ11+xp7a0NtnSjsf/dT3S2nZcuW+u2335z2k/pijNGxY8ckyal1wv73kKS0tLRKrauq+2FhYaHS09Mlld69yV6O6mzD1bderrjbP8q2RFVmmersQ5XZN119C7x8+XJdfPHFTkEqJCREQUFBstlsKi4udtRjdna2Rx+Wa99H7Xfxc8d+LnO3T1fmvUvVPzZPdczZ57sqn/1WzvZW4LLCwsLUo0cPrVmzRvPnz1efPn20bNky5efna9iwYfLx8dGwYcP05JNPav78+XrwwQeVm5urlStXSqrdUFP2GK3MnTQl5+PngQce0IYNG/TZZ5/p3Xff1bvvviubzaYuXbrowgsv1M0336yOHTt6vNxlVfVYK3suquizuSZ3LHvllVcklbbY2tdzxhln6Mcff9SwYcP09ddfa+TIkZo1a5bj4nnx4sWSVKnWYk851Tnv9ddf11133eUIvjabTWFhYY7jODc3V8ePH69Wq7NUu5+11Vm3fd841TVbixYtnB6eWR3x8fG68847deedd0oq/TJm9uzZevbZZ7V582atW7dOt956q+OOa67KUFH5pNLPgiNHjrh9SKsneXt7a9q0abr88su1e/duTZw4URMnTlRQUJD69eun0aNHa/z48fX60HRaaqqp7Lda69atq/H6Kts1q+xy9nT8r3/9S6Z0fFSFPxXdHrk2eaLbmZ1V3nNlVOdvXl+2bt3q+NYxISHBMb3sNzQHDx6s1N/E1S06K1J2G9OmTavUNqZOnepyXbX9hO36UlRUpKuvvloZGRnq3r27/ve//+n48ePKzMzUoUOHdPDgQadb9nqipdmVhr5PV3e7Bw8e1KpVqxQcHKzhw4e7XObklhj7v/ZvVO1dzJYuXarCwkL99NNPys/PV1BQUIXfONeU/fgJDAys1LFjjHFqwfD19dX06dO1fv16/fOf/9SwYcMUFBSkzZs368UXX9QZZ5yhl156qdbKXx1l9++K/ubVPQ5ycnIctzo+uSUkKSlJP/zwgyIiIvTjjz/qggsu0LFjx1RUVKQPP/xQkjRhwoRqbbc6Kjrn/frrr7r77rtVUlKiK664QqtWrVJeXp6OHj2qgwcP6uDBg5o8ebKk2jtn1DX7+zjVuaA23m9ERIT+9Kc/aeXKlercubMk6csvv3TbUtUQPvtP1q1bN23dulVffPGFbrnlFp155pnKzc3Vjz/+qL/+9a/q1KmTNm3aVG/lI9RUU9muQ19++WW11lH2G5SKvhEo2+xb9iFO9jE49bkDVcTevF7V57dUpKG/58qw/91P9S2Q/e9e9m9eX7777jvH72UveMqOA6utv4n9GUS1uQ2rW758ufbu3Stvb299++23uuiii8p9i2lvOa0N9n06LS2twn7i9b1Pn6oLjf3ZDyd/u/3111/LGKMLLrjA7dgXe3j56aefVFBQUC7U+Pv7q1+/fsrOztbKlSsd8wcMGCBfX9/qv6lTsB+jubm52rlzZ7XX061bNz3++OOaN2+eMjIy9OOPP2rQoEEqLi52tOY0FGX/fmVbqk5W0byKZGZmVnhx3KNHD82dO1dhYWH66aefNGzYMD311FNKSUnRsGHD1K9fv2pt19NmzJih4uJide7cWdOmTVPv3r3l5+fntExtnjfqg33fONXfvrr7RmUEBQXp2muvlVT67Kuy48HKquh8ZT9X+fj4VHtcd3X5+flp9OjReuedd7Rp0yalpaXp7bffVmRkpFJSUjR+/Pg6LU9ZhJpqiouL05gxYyRJn3zyibZv317p19pPhm3btnXsjGUfXnYy+ziBqKgoR9cz6Y9viL777rtKdcWqa/YT95o1azw2KLK+37M9yNbkW5xevXpJKh0k7O7BY1u3bnWctNyN3agrGRkZevXVVyWVttIMGDDAMe/MM89UkyZNJFV/wKL9oqCiOrX/3T///HO3dXY6swfkmJgYt10W7OcRV2q6X9v36aKiIscDaisqQ33t0ykpKUpOTnY5LzMz0zEexv5+7OzjaewD012xh5OcnBz9+OOPWr16tSIiItS9e3fHMvaAM3/+fMdNAmqz65lUeh62H2OeGlTs4+Oj4cOH67vvvpO/v7+MMeX2r8oc17WlXbt2jkHNp3qAc3XExMQ4znvuPrt79eqlOXPmKDQ0VD///LMef/xx+fv76/XXX6/WNmuD/bzRrVs3t+NeKjpvWFHPnj0llV6XuOtSt2vXrhp3PTuVsuMm3XXZtZ8jKpqXlJTkkS9Fyv79q3rMRkVF6dZbb9Vzzz0nqbT3Un3dSIBQUwNPPfWUQkJClJubq9GjR5/yCa9Hjx7VmDFjHGMCbDabrrzySknSO++84/Ibkd9//13vvPOOJOnqq692mnfzzTfLZrMpIyNDDzzwQIXbLiwsrPMQcMUVV6hJkyYqKirSPffc45EPt/p+z/YPsuoMALe76qqrJJV+02K/q9fJ7Hdoio6OrvAmErXtyJEjGjNmjOMbo6efftqpH7uPj4+jK8UHH3xwyjvkuGpmr0yd3nLLLZKk7du364UXXqhwG9nZ2SooKKhwmcbG3pJ16NAhl+Mm9u/fr3//+99uX1/T/TopKclxI4KnnnrK5cDR//3vf44xJCefy+qS/c6CJ3vppZeUm5srHx8fjR492jE9KytL8+fPl7e3t2PQvCshISGOsPbEE0+oqKhIQ4YMcbpYsAeYr7/+2umGIbUpNjbWEcZeeOGFU34Bd/IxWlHLm7+/v6N708ndnDxxrqwum83m+Bu+/fbbLm8ssWPHDsfdR6vKy8vL8aXmO++8o9WrV7tc7pxzznFc6EmlN6qoyTgeTyvbAu7q83n27NkNugt3dYwePVpeXl7Kzs52fFl3sqeffrra61+1atUpb3xQVFSkjz/+WJIUHBysxMREl8u9/fbbjnGQZW3bts0xDsd+DVlT9uNVcn/MnupubYGBgY7f66urN6GmBjp27Kj//ve/8vPz05YtW9S9e3c999xzTk38xcXFWrdunf75z3+qXbt2jltr2v39739XeHi4jhw5onPPPddxxzCptBvDueeeq4yMDEVGRpa7HWf37t119913Syrd+a+44gqtX7/ecXIqLi7Whg0b9OSTTyohIUHr16+vnYpwIywsTM8//7wkafr06br88sudynD06FF99913uuyyyyp9N536fs9nnnmmpNILtFOFWHf69Onj+ED829/+ptdff90xMPfgwYO6+eab9fnnn0sqvQCrrVu9ulNYWKi1a9fqiSee0BlnnOHoJvPII4+4PIE++uijSkhIUFFRkS688EJNnjzZaaDusWPHNGfOHI0fP14DBw4s93p7nX788cduB/hfdtlluvzyyyWV3oXpL3/5i9PFWUFBgVauXKmHHnpI8fHxDeLmCnVpwIABCg4OljFG48aNc9RNcXGxvv/+ew0ZMqTC/tn2v8Hx48erfaFnv3hbsmSJxo4d67hTY2FhoT7++GNHkOnXr5/LwfZ1ISwsTB988IHuuusux8VCZmamnnnmGUfYuf32250uPOfMmaP8/HwNHDjwlN087AHFHt5OvntRnz59FBISorVr16qoqEihoaGOO67VppdeeklRUVE6fvy4BgwYoP/85z9ON9xIT0/XzJkzNXr06HKBMz4+Xg8//LBWrFjhdFGzc+dOXXPNNcrJyZGXl5fT7c6lyh3Xtenvf/+7AgMDdejQIZ1//vmOsa/GGM2fP18XXHBBjQY0P/nkk4qNjVVeXp6GDh2ql19+2enb6W3btunBBx903DbYZrNp586dGjVq1CkvDuvKhRdeKEnasmWLbr/9dsfFeHZ2tt555x2NHTvW5W3rrSw+Pl5//vOfJZV+efjiiy86vvw8fPiw7r33Xv3nP/9xtPRV1Weffab4+HhNmDBB3377rdM+kZOTo9mzZ2vo0KFatWqVpNJbjpcNA2UVFhbqvPPOc4Rme4voBRdcoPz8fLVq1crxyI+a6tixo6Pr4Xvvvecy5E6bNk39+/fXO++8o127djmm2z9n7Neoffv2rXb91Vi1nm4DJ0uXLjXt27d3egCXn5+fiYyMdDzkSZKx2Wzm6quvNgUFBU6vX7hwoeNJ1zrxYCP7QwSl0ifbLl682OW2i4qKHA9+s/8EBASYqKgoxxOi7T9Lly51em1tP3zT7plnnnGqh8DAQMdDOe0/R48edXqNfbqrB7fV5D1X9EAvu4oeRLh9+3YTEBBgpNKnEcfFxZn4+HgTHx9vUlJS3K7zZBkZGU4PEPPx8TERERGOp5pLMvfff7/L13ry4Zv292D/adKkiVMZpNKnFp/8ENOT7dq1y3Tr1s3pdeHh4Y4Hx9p/XD048b///a9jvq+vr2nRooWJj483/fv3d1ouOzvbXHXVVU7rCw4ONhEREU77l6RyD+is7ENT7Q/fdPewOGNO/VDBio6ryjx809WD7Owq+tu/9dZbTnUQEhLi2Fejo6OdHn7p6ngfPny4Y35oaKhjv3755ZcrXcbJkyc77T/h4eGOh8RJMl27dnX5YMvKPPyzMucrd8qW+8EHH3Ts+5GRkcbb29ux3nPPPbfcQzCvvfZaI8mpHtyZN2+e099gy5Yt5Za58MILHfMvvvjiKr2PilT08E1jjPn5559NmzZtnD6PIiIiTEhIiFOZT36wa9l5Xl5eJiIiwrFf2dfjqm4qc1zX9GGAZcvn6nj8/PPPnT4TQkNDTVBQkJFkWrRo4djv/P39K9yGO5s2bTIdO3YsV6eBgYFO56hXX33VzJo1y3GeuuKKK2r8gM7KPnzzVE4+p4aHhzuOibPOOsu89tpr1Tpn1fSztjIP36zofF5R2TIzM82AAQMc79nb29vp8/eRRx4xgwYNMpLMs88+63YbrkycONGpPiWZoKAgp2s8+891111X7nqw7DExbdo0x7VSSEiIY9+1/51Wr15dbvvVffimMX88sNZe5tatW5v4+Hhz3333GWOcH5JsP26ioqKcPn+bN29ufv311yrVmSfRUuMB/fv319atW/Xpp5/qmmuuUfv27RUQEKDMzExFRkZqwIAB+sc//qFff/1Vn3zySbn+j4MHD9bWrVt13333qXPnziopKZExRp07d9b999+vX3/91eU33FJpE9/LL7+sn3/+WbfccosSExMdz0uIiIhQ//79NWnSJK1fv77Sz+jwtIcfflgbNmzQzTff7HhGhDFGiYmJuvrqqzVz5kynps9Tqc/33KFDBy1YsECXXnqpYmJidPjwYe3du1d79+51eZtdd8LCwjRv3jy9//77GjJkiEJDQ5WVlaWmTZtqzJgxWrBgwSm7WXlCSUmJo8tSamqqjDFq0aKFBg0apLvvvltz5szR7t27T/nNetu2bbVmzRp9+OGHGjlypJo1a+boBta2bVtdfvnl+s9//qPly5eXe+21116r//73vxowYICCgoJ04MAB7d27t9wgyaCgIH366adasGCBrrvuOrVr104lJSXKyspSbGyshg0bpueff147duxoUF086sptt92m7777TkOGDFFISIiKiorUokUL/e1vf9OGDRvcPqzWbsaMGbrnnnvUsWNHFRYWOvbrqnQfuueee7RmzRpde+21atWqlXJychQYGKhzzjlHkydP1qpVq6p1+3tPeu655xzfOJaUlMjPz0/du3fXq6++qjlz5ji1jBYVFTluklHReBq7fv36OfrHx8XFObrklVW29aa2u56V1aNHD/3yyy96/fXXde655yo6OlqZmZkqKSlRhw4d9Kc//UnTpk0r15tg7ty5evjhhzVw4EC1atVKubm5kqT27dvrxhtv1OrVqx2t52VV9riuTWPHjtWaNWt0xRVXKCYmRvn5+YqLi9Ndd92ldevWObpfVfdb5TPPPFPr16/Xm2++qWHDhikqKkqZmZkKCgpS//799dRTT2nPnj268847ddlllzlaMz///HPdddddnnqbNfLxxx/rlVdeUVJSkvz9/VVcXKyuXbvq2Wef1U8//eT2mVlWFhISonnz5umFF15QUlKS/Pz8ZIzR4MGDNXPmTD355JOO815V941nnnlGK1as0OOPP64LL7xQbdq0kTFGWVlZCgsLU7du3XTrrbdq6dKl+vDDDyscD3P22WdrzZo1uv766xUWFuY4p998883atGlTubF/NfXGG29o0qRJjlbWffv2ae/evY5W7UsvvVQffvihbrzxRnXr1k1hYWE6duyYQkND1adPHz355JPasmWLOnXq5NFyVYXNmEZynz4AADxo/vz5Gj58uLp27Vrtp56j4frHP/6hZ555RsOGDavwZj04vWRlZSkqKkoFBQVavHix2y+Va8OePXscN4TavXu32rRpU2fbbgxoqQEAwIWKHrgJa0tLS3PcqMU+tgSQpMmTJ6ugoECRkZH1fvdRVA2hBgAAF7p06aLHHnusXp+7gOr797//rX/961/auXOno3twfn6+/ve//2nQoEFKTU1VTExMnT4ME/UvMzNTV111lebMmePUvXbv3r164IEHNGnSJEnS3XffXec36kHN0P0MAAA0Onfffbfjtr3e3t4KCwvT8ePHHQEnLCxMs2bNcnqgMBq/jIwMRUREOP5vf1BxZmamY9qYMWM0bdo0p0cY1AW6n9VM3f61AAAA6sD48ePl7e2txYsX67ffftPhw4cVGBiotm3b6oILLtBdd911Wt5U5HQXEhKi119/XT/88IM2b96stLQ05ebmqlmzZurVq5euv/56jRkzpsLb4KNhoqUGAAAAgKUxpgYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApZ22t3Ru2rSpsrOz1bp16/ouCgAAAHDa27dvn4KDg3Xw4MEqv/a0banJzs5WYWFhfRcDAAAAgKTCwkJlZ2dX67WnbUuNvYVmy5Yt9VwSAAAAAF26dKn2a0/blhoAAAAAjQOhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWJpPfRfgtPbzh5JPoOQXJPkFS77BJ/0eLPkGSjZbfZcUAAAAaLAINfWlpFj6+m+VWNAm+Z4IOn5Bkl/Iif+X/d0egMr8fvL/fU8s7xf0x3Rv31p/mwAAAEBtI9TUl4LsSi5opMLs0p/KvqSyvP3ctxD5Bbn//VTBitYlAAA8p6REKimSTHHpl6I+AZI3l3BAWRwR9cUUS20HS4U5UkGOVJB14vfs0n/rQnGBlFsg5R718IptFbQWVaZVqYJgxUkcABo3YyRz4iK+pPjEvyd+Nyf932l+UZnXuVnGnPyaYud/K1z/ydsv+iNs1Gj7J893US6Z8vXk7ee6F0bZz9RyX0AGufgi08Vrvbzr/M8O1BRXiPUlMEIa/7XreSUlUlFuacCx/9gDj+P3rNIwVPb3ghMtOk6/n/i//feSojp4c+ZEmbI8v2ovn9JvqHz8Xf/r7VfBfDevKffaCl7v7UcrVENXUiwVF5aG9pKiMr8XSsVFZX4/8VNSWPoaSU4XDqbcL6UXW26nlZle2WmnXGdVtlPF8lR32zabZPMuPRa9vE/8+JT+2Mr+v8y/tjLLlH2N03Svk9ZzYhqqr6S4dH+37+tO+36B8zFQXHDi5+RjxNVyhScdYx56bdmLepyave7yMjy/bp+AU4SksoGoEiHJ0ZMjiOMatYZQ0xB5ef1xMvC0ogLnsONoITqptejkIOUyWJX5va5al0qKai8wVZbLQHSq0FTR/CqGsdr+Bs2Yky5Cyl6ouPvdflHi5vdThYpKv8bd68v8bkpqt35Qh2zVCEieClqVWY+PZPM6aT1l1m+zndgv7RfvrsJFmYv9k/d/pwv/arzW1bf7QGUU5ZX+5B7x/Lrt4cZlN/cg161PbgNWHXV9N8ZFa12xi/+Xba0rO69s98FTvfbkVsOKXlt22ZP/f/JrXZTP1f/73i51HVs79VjLCDWnGx+/0p/ACM+ut6Tkj3BTlZYjt8HKHpqySg/GhsR+stex+tn+ya1VLgORf+my1QkIfEuKBsOc2CcL67sgaIicgulJrX3lAqer+ScFV5dB9qSwWvbfcsG4Msuc9P9TvgdXr/Eq/Qxy+pIxx8VnbI6Lnh2uvqA8sXxdfSFkv1bw+HehJ91YyR6SZDv1hf+pwsbp9AVB5sH6LkG1EWrgGV5ekn9I6Y9iPbdeY0ovvO0n36L8P0KF4/ey/+a7mF7m9+KCCl6bV9qSVfb/DfFiqiG0VlmSrTQAevuWXhyU/d3Lu3S+dNI3fVWc5jT9VNNOKlutbaeiaVXZ9gnGlB8X4DSOwNVFw0ljD0wxLWr1yeZ9Yv/3Kx2n6O0nefmWHg9up5343euk/3v7OR9Pjmm+zv+vzHInBwS3oeJEYKErsOcYcyIo5bj4MtLdNBe9N1x9QVno6bscuX0TtXdjpdOJhb/YJNSgYbPZyrQ8RNb99kuKnYNPsavQdHKoqiA0uQ1VLgKV/d+G9A2RV9kLG9+TLnRO/t2vfHhw9bvb1590AVXl15+8fQa+NiiOb0crORC8ooDkcsD1yUGrsuuvaGB3FYOcMRVc5Jfdv+37aWUDQnVeW+Z1jGnAyWy20u5bvoGSojy7bmOkwtxKBqJKhiR7wCrK9WxZa8reOlh2XODJ4dzRglg2vJ/8Ou+TWvLK/r/s61x1nfU6ab67bbpZV1zX+q7FaiPUABXx8j4xADKofrZvH9/iMhBV1EqV98dJrEqhwH5h5CaU8M0oPMXLS5IXz8sCGjubrcznaIxn1+3U9d1NIJIqFxoqFRLKdAF0FRL4jKxXhBqgIbPZ/hgHBQAA/uDU9R2nO9qgAQAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApRFqAAAAAFgaoQYAAACApXks1OTl5emxxx5Tx44dFRAQoObNm2vChAnav39/ldc1e/ZsnXfeeQoPD1dQUJC6du2qF154QUVFRZ4qLgAAAIBGwiOhJi8vT8OHD9cTTzyhrKwsXXbZZWrVqpWmTJminj17Kjk5udLreu6553TxxRdr/vz5OuOMM3TeeecpNTVVDz74oEaMGEGwAQAAAODEI6HmmWee0bJly9S3b19t375d06dP18qVK/XSSy8pLS1NEyZMqNR6Vq9erYcffli+vr6aPXu2li1bpq+++krbt2/XoEGDNHfuXL300kueKDIAAACARqLGoaawsFCvvfaaJOmNN95QSEiIY969996rpKQkLV68WGvXrj3lut555x0ZY3TDDTfo/PPPd0wPCwvTm2++KUl66aWXVFxcXNNiAwAAAGgkahxqli5dqoyMDCUkJKhHjx7l5o8dO1aS9M0335xyXfbgM2TIkHLzunTpoujoaKWlpWnZsmU1KzQAAACARqPGoWbDhg2SpJ49e7qcb59uX64i2dnZkqSIiAiX8yMjIyu9LgAAAACnB5+armDfvn2SpJYtW7qcb59uX64iMTEx2rFjh/bu3VtuXklJiVJSUiRJe/bsqXT5unTp4nJ6cnKyEhISKr0eAAAAAA1TjVtqsrKyJElBQUEu5wcHBzstV5HBgwdLkj744INy86ZPn67c3FxJUmZmZrXKCgAAAKDxqXFLjTFGkmSz2SqcXxm333673nzzTa1YsUI33HCDHnnkEUVHR+v777/X7bffLh8fHxUVFcnLq/JZbMuWLS6nu2vBAQAAAGAtNW6pCQ0NlfTHeJiT5eTkSJLTXdHcadGihb788ktFRkbqgw8+UIcOHRQREaGrrrpKrVq1ctwa2t2YGwAAAACnnxq31LRu3VqStH//fpfz7dPty53K0KFDlZycrOnTp2vjxo3y8vLS2WefrSuuuELXX3+9JFpZAAAAAPyhxqGmW7dukqSff/7Z5Xz79KSkpEqvMzw8XLfeeqvTtKKiIi1atEheXl4aNGhQNUsLAAAAoLGpcfez/v37KywsTMnJyVq3bl25+TNmzJAkjRw5skbb+fjjj3Xo0CFdeOGFatWqVY3WBQAAAKDxqHGo8fPz0x133CFJuuOOO5zG1kyePFkbN27UgAED1Lt3b8f0119/XZ06ddLDDz9cbn1r164td3OBH374QX/7298UEBCgyZMn17TIAAAAABqRGnc/k6RHHnlEP/74o5YtW6YOHTpo4MCB2rt3r1auXKmoqChNmTLFafn09HRt27ZNBw4cKLeuMWPGqLi4WF27dlVYWJi2bdumdevWKTAwUDNmzFBiYqInigwAAACgkahxS40kBQQEaMGCBXr00UcVFBSkWbNmac+ePRo/frzWrVun9u3bV3pdt912m1q0aKGVK1dq5syZOnLkiG655RZt3rxZI0aM8ERxAQAAADQiNlOVB8k0IvY7qLl7jg0AAACAulOT63OPtNQAAAAAQH0h1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNEINAAAAAEsj1AAAAACwNI+Fmry8PD322GPq2LGjAgIC1Lx5c02YMEH79++v8rrmzJmjiy66SNHR0fL19VVsbKxGjhypefPmeaq4AAAAABoJj4SavLw8DR8+XE888YSysrJ02WWXqVWrVpoyZYp69uyp5OTkSq9r8uTJuuiii/T999+rc+fOGjNmjNq0aaPvvvtO5557rt5++21PFBkAAABAI+GRUPPMM89o2bJl6tu3r7Zv367p06dr5cqVeumll5SWlqYJEyZUaj1paWl6+OGH5efnp8WLF2vJkiWaNm2aVq1apRkzZshms+m+++5TVlaWJ4oNAAAAoBGocagpLCzUa6+9Jkl64403FBIS4ph37733KikpSYsXL9batWtPua6VK1eqoKBAw4YN04ABA5zmjRkzRklJScrJydEvv/xS02IDAAAAaCRqHGqWLl2qjIwMJSQkqEePHuXmjx07VpL0zTffnHJd/v7+ldpmZGRk1QoJAAAAoNGqcajZsGGDJKlnz54u59un25erSO/evRUWFqb58+dr6dKlTvNmzpypjRs3ql+/fmrfvn0NSw0AAACgsfCp6Qr27dsnSWrZsqXL+fbp9uUqEh4ervfee0/XXHONBg0apP79+6tFixbavXu3Vq9erQsvvFBTp06tUvm6dOnicnpycrISEhKqtC4AAAAADU+NQ4190H5QUJDL+cHBwU7LncrYsWMVGRmpK6+80qm1Ji4uTsOGDVNUVFQNSwwAAACgMalx9zNjjCTJZrNVOL+yXnrpJZ133nkaNGiQNm7cqKysLG3cuFF9+/bVAw88oCuvvLJK69uyZYvLH1ppAAAAgMahxqEmNDRUkpSdne1yfk5OjiQ53RXNnUWLFun+++9X9+7d9fnnn6tr164KDg5W165dNWPGDPXo0UNffPGF5s6dW9NiAwAAAGgkahxqWrduLUnav3+/y/n26fblKvLhhx9KkkaPHi0vL+eieXt7a/To0ZKkhQsXVre4AAAAABqZGoeabt26SZJ+/vlnl/Pt05OSkk65LnsAatKkicv59ulHjhypcjkBAAAANE41DjX9+/dXWFiYkpOTtW7dunLzZ8yYIUkaOXLkKdfVtGlTSdKaNWtczl+9erUkqU2bNtUsLQAAAIDGpsahxs/PT3fccYck6Y477nAaWzN58mRt3LhRAwYMUO/evR3TX3/9dXXq1EkPP/yw07pGjRolSfr444/LPazzq6++0ieffCIvLy9dfvnlNS02AAAAgEaixrd0lqRHHnlEP/74o5YtW6YOHTpo4MCB2rt3r1auXKmoqChNmTLFafn09HRt27ZNBw4ccJo+atQoXXHFFfr888916aWXqlevXmrbtq12797taL15+umnlZiY6IliAwAAAGgEatxSI0kBAQFasGCBHn30UQUFBWnWrFnas2ePxo8fr3Xr1ql9+/aVWo/NZtP06dP1/vvva9CgQdq5c6e+/PJL7dmzRxdffLFmz56tv//9754oMgAAAIBGwmaq+iCZRqJLly6SSp9jAwAAAKB+1eT63CMtNQAAAABQXwg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAADA0gg1AAAAACyNUAMAAACc5gqKSuq7CDVCqAEAAABOQ8YYrdlzRPd9tkHnPDtPx/MK67tI1eZT3wUAAAAAUHeOZhdo5rrfNG3VPu1IzXJM/2r977runPh6LFn1EWoAAACARs4YoxW7jmja6n2avfmgy+5mszcdINQAAAAAaFjSs/L1xdr9mr46RbvSs10u0y8hSlf3aa3zu8TVcek8h1ADAAAANCIlJUbLkg/r01X7NPeXgyosNuWWiQ7x09izWumq3q3UJjq4HkrpWYQaAAAAoBFIPZ6nz0+0yuw7klNuvs0mDewQo6t7t9LwznHy82k89wwj1AAAAAAWVVxitHhHmqat2qcff01VcUn5VpnYUH9d2buVxvVqpVaRQfVQytpHqAEAAAAs5sCxXH22er8+W5Oi3zJyy833sklDEmN1dZ/WGpoYIx/vxtMq4wqhBgAAALCAouISLdyWpk9X7dOCbaly0Sij5mEBGneiVaZ5eGDdF7KeEGoAAACABmz/0Rx9tjpF09ek6NDx/HLzvb1sGt6ptFVmUMcYeXvZ6qGU9YtQAwAAADQwhcUlmvfrIX26KkWLd6TJuGiVaRkRqKv7tNbYs1oqrklA3ReyASHUAAAAAA3E3sPZmrY6RZ+v2a/0rPKtMj5eNp3fJU5X92mt/gnR8joNW2VcIdQAAAAA9Si/qFg//HJIn67ap592Hna5TJuoIF3Vp7XG9GypmFD/Oi5hw0eoAQAAAOpBclqWpq9O0Yy1+3Uku6DcfD9vL114ZlNd1aeV+raLks1Gq4w7Hru3W15enh577DF17NhRAQEBat68uSZMmKD9+/dXeh1Tp06VzWY75c+HH37oqWIDAAAAdSavsFiz1v2mce8s1/CXFun/Fu8qF2gSYoL1yIjOWvH34fr31T3ULyGaQHMKHmmpycvL0/Dhw7Vs2TI1a9ZMl112mfbs2aMpU6bo22+/1fLly5WQkHDK9bRv317jx493Oe/YsWOaNWuWJGnAgAGeKDYAAABQJ7YfytSnq/Zp5s+/6VhuYbn5/j5eGpHUTFf3aa1e8RGEmCrySKh55plntGzZMvXt21dz585VSEiIJGny5Mm67777NGHCBC1atOiU6xkwYIDbwPLWW29p1qxZ6t+/v9q1a+eJYgMAAAC1JregWN9u/F3TVqdo7d6jLpfp1DRUV/dprVHdWygsyLeOS9h41DjUFBYW6rXXXpMkvfHGG45AI0n33nuvPvjgAy1evFhr167VWWedVe3tfPTRR5Kk6667rmYFBgAAAGrRL78f16er9mnW+t+UmVdUbn6gr7cu6dZMV/VprR6twmmV8YAah5qlS5cqIyNDCQkJ6tGjR7n5Y8eO1caNG/XNN99UO9Ts3r1by5Ytk5+fn8aNG1fTIgMAAAAelZ1fpG82/K5PV+3Thv3HXC7TpXkTXd2ntS7r3lyhAbTKeFKNQ82GDRskST179nQ53z7dvlx12FtpRowYoYiIiGqvBwAAAPAUY4w2/XZMn65K0dfrf1N2QXG5ZYL9vHVZjxa6undrdW0ZVg+lPD3UONTs27dPktSyZUuX8+3T7ctVx8cffyyJrmcAAACof8fzCvXV+t81bdU+bfn9uMtlurUK15/6tNLIpOYK9ucpKrWtxjWclZUlSQoKCnI5Pzg42Gm5qlq1apW2bdumiIgIjRgxosqv79Kli8vpycnJlbojGwAAAGCM0bqUDH26cp++3XhAuYXlW2VCA3x0eY8Wuqp3a53RvEk9lPL0VeNQY4yRJLcDnOzzq8ve9ezKK6+Un59fjdYFAAAAVMWxnEJ9uW6/Pl2Vom2HMl0u0ys+Qlf1aa0RXZsp0M+7jksIyQOhJjQ0VJKUnZ3tcn5OTo4kOd0VrbKKioo0ffp0SdXverZlyxaX09214AAAAOD0ZozR6j1HNW3VPn236YDyi0rKLRMW6KsxPVvqqj6t1DEutB5KibJqHGpat24tSdq/f7/L+fbp9uWqYu7cuUpNTVW7du3Ur1+/6hcSAAAAOIUj2QWa+fN+fbpqn5LTXH9hf3bbSP3p7Na6oEtTBfjSKtNQ1DjUdOvWTZL0888/u5xvn56UlFTlddu7nl177bXVLB0AAADgnjFGy3cd1qerUvT95oMqKC7fKhMZ7KexZ7XUlb1bKSGm6r2PUPtqHGr69++vsLAwJScna926deWeVTNjxgxJ0siRI6u03qysLH311VeSCDUAAADwrLTMfH3x835NW7VPew7nuFxmQPtoXdWnlc47I07+PrTKNGReNV2Bn5+f7rjjDknSHXfc4TS2ZvLkydq4caMGDBig3r17O6a//vrr6tSpkx5++GG36505c6ZycnJ0zjnnqEOHDjUtJgAAAE5zJSVGi7en6S8frVXfZ+fpX7O3lgs00SH++uuQBC16YIg+uulsjUxqTqCxAI/cNPuRRx7Rjz/+qGXLlqlDhw4aOHCg9u7dq5UrVyoqKkpTpkxxWj49PV3btm3TgQMH3K7T3vWMZ9MAAACgJg4dz9Pna1I0bXWK9h/NLTffZpMGd4zRVb1ba3jnWPl61/h7f9Qxj4SagIAALViwQM8++6w++eQTzZo1SxERERo/fryefPJJtWrVqkrrO3DggObPny9fX19deeWVnigiAAAATiPFJUaLtqfq01Upmr81VcUl5R8z0rRJgMb1bqVxvVqqZYTrZy7CGmympg+SsSj7LZ3d3fIZAAAA1nI8r1DLkw9ryY40zfs1VQeO5ZVbxssmDesUq6t6t9aQxBj50CrTYNTk+twjLTUAAABAXSsuMdr02zEt3p6mJTvS9PO+DJctMpLUIjxQV/ZupSt6tVSzsMA6LilqG6EGAAAAlnHgWK6WbE/Xoh1p+mlnujJyCt0u6+Nl07md43RVn1Ya2CFG3l62Oiwp6hKhBgAAAA1WbkGxVu4+rMXb07VkR5p2pGZVuHx4kK8GtI/WoA4xGtIpRrGhAXVUUtQnQg0AAAAaDGOMth7MPNGlLF2r9hxRQVH5B2La+XjZ1LN1hAZ2iNagjjE6s0UYLTKnIUINAAAA6lV6Vr6W7kjX4h2lQSYtM7/C5eOjgkpDTIcY9U2IUmiAbx2VFA0VoQYAAAB1qqCoRGv2HtGSHelavD1NW34/XuHyIf4+6psQpUEdYzSoQ7Tio4LrqKSwCkINAAAAapUxRrvSs7Vke5oW70jXil2HlVNQ7HZ5m01KahGmQR1jNLBDjHq0DueBmKgQoQYAAAAedyy3UMt2pmvxidaY3zJyK1y+aZMADeoYrYEdYjSgfbQigv3qqKRoDAg1AAAAqLGi4hJt2H9MS3akafH2NK1PyZCbR8ZIkgJ8vXR22ygN7BCtwR1j1D42RDYbA/xRPYQaAAAAVMv+ozmOcTE/7UzX8byiCpfv1DT0xLiYGPVqE6EAX+86KikaO0INAAAAKiU7v8jxzJjFO9K0Ky27wuUjg/00sENpl7JBHaIV24RnxqB2EGoAAADgUkmJ0S8Hjpfeanl7utbsPaLCYvd9yny9bTorPkIDO8RocMcYndGsibx4ZgzqAKEGAAAADqmZeVqyPV1LdqRp6c50pWcVVLh8u+hgx4Mvz2kXpWB/Li9R99jrAAAATmN5hcVau/eoFm9P06Ltadp6MLPC5UMDfNQ/IfrE7Zaj1SoyqI5KCrhHqAEAADiNGGOUnJalRSdaY1bsOqy8whK3y3vZpG6twjWoQ4wGdYxWt5bh8uGZMWhgCDUAAACNXEZOgZbuTHd0K/v9WF6Fy7cID3Q8M6Z/QrTCgnzrqKRA9RBqAAAAGpnC4hKtT8nQku1pWrQjXRv3Z8hU8MyYQF9v9U2IcoyNaRcdzDNjYCmEGgAAgEZg3+EcLT7x4MvlyYeVmV/xM2O6NG9SeqvljtE6Kz5C/j48MwbWRagBAACwoKz8Ii1PPqzF29O0ZEea9hzOqXD56BB/DTrREtO/fbRiQv3rqKRA7SPUAAAAWEBRcUnpM2O2p2nxjnT9vPeoikrc9ynz8/ZS77YRGtQhRgM7xKhzs1C6lKHRItQAAAA0QIeO52ndvgytSzmq9fsytHH/MeUWFlf4mvaxIaUhpmO0zmkbpUA/upTh9ECoAQAAqGd5hcXa/NsxrduXofUpGVq37+gp71AmSWGBvhrQPtpxp7Lm4YF1UFqg4SHUAAAA1CFjjPYcztH6lKOlLTH7MvTrgeMVdiWz8/GyqXurcMeDL5Nahsvbiy5lAKEGAACgFh3LLdSGlIwTrTBHtT4lQ0dzCiv12uZhAerROkI9Woere6twndkiTAG+dCkDTkaoAQAA8JCi4hJtO5R5ogtZaTey5LTsSr020NdbSS3D1L11uHq0Kg0ycU0CarnEQONAqAEAAKimsoP51+3L0KZKDOa3S4gJdmqFSYwLlY+3Vy2XGGicCDUAAACVUN3B/JIUHuSrHq3C1f1EC0y3VuEKC/St5RIDpw9CDQAAwEnsg/nX7Tvq6EpWlcH8ZzRvou6twtXjRFey+KggnhED1CJCDQAAOO2VHcy/7sRg/oxKDuZvER7oCDAM5gfqB6EGAACcVuyD+ct2I6vqYP4erSMcQYbB/ED9I9QAAIBGrXQw/1GtO9ESU5XB/O1jQ5y6kXWMC2EwP9AAEWoAAECjUXYw/7qUo1q/L6PSg/kjgnxPBJjSwfxJLRnMD1gFoQYAAFiSJwbz92gV7nguDIP5Aesi1AAAAEs4llOo9fsztL6Gg/l7tA5Xl+YM5gcaE0INAABocMoO5i8d0M9gfgDuEWoAAEC9q+lg/rLdyBjMD5x+CDUAAKDOHcsp1OIdaVqwLVUrkg9XaTB/2RYYBvMDkAg1AACgDhhjtOX341q4LVULt6Xp531Hdarx/GUH89uDDIP5AbhCqAEAALXiWG6hlu5ILw0y29OUlplf4fItwgNPdCFjMD+AqiHUAAAAjzDG6NcDmVq4PVULt6Zp7b6jKq6gOSY6xF+DO8ZoSGKMzm4bqVgG8wOoJkINAACotsy8Qv20M10LtqZp0fY0HTzufmyMl03q3ipcQxNjNSQxVl2aN5GXF13JANQcoQYAAFSaMUbbD2Vp4bZULdiWqjV7jlb4sMvIYD8N6RijwYkxGtQhRhHBfnVYWgCnC0INAACoUHZ+UWlrzLY0LdqWWuGdymw2KalluIYmxmhoYqy6tgijNQZArSPUAAAAJ8YYJadlacHWNC3cnqpVu4+osNh9a0x4kK9jbMygDjGKCvGvw9ICAKEGAABIyiko0vLkw1pw4pbL+4/mVrh8UsswDekYoyGdYtWtZbi8aY0BUI8INQAAnIaMMdqdnq0F29K0cFuqVu4+ooKiErfLNwnw0aCOMRqSGKvBHWMUE0prDICGg1ADAMBpIregWCt2HT4xyD9N+47kVLh8l+ZNNOTE2JjurcLl4+1VRyUFgKoh1AAA0IjtSc92hJgVuw4rv4LWmFB/Hw3sGK0hibEa0jGG58YAsAxCDQAAjUheYbFW7j6ihSfGxuxOz65w+U5NQzUkMVZDE2PUMz5CvrTGALAgQg0AABaXciTH0RqzLDldeYXuW2NC/H3Uv32UhibGanBijJqFBdZhSQGgdhBqAACwmPyiYq3effTEncpSlZxWcWtMx7gQR4jpFR8pPx9aYwA0LoQaAAAs4LeM3NLWmK2lrTE5BcVulw3y81a/hGgN7VR6t7IW4bTGAGjcCDUAADRABUUlWrP3iBaeuOXy9kNZFS6fEBOsoYmxGpIYq95tI+Tv411HJQWA+keoAQCggThwLNcRYpbuSFd2Ba0xAb5epa0xiaWtMa0ig+qwpADQsBBqAACoJ4XFJfp571HHAzC3HsyscPm20cEaciLEnN02UgG+tMYAgESoAQCgTh06nqdF29K0cHuqlmxPV2Z+kdtl/X281DchSkM6lgaZNtHBdVhSALAOQg0AALWoqLhE61IyHIP8fzlwvMLlW0cGObqUndMuSoF+tMYAwKkQagAAlZKVX6TU43mO/5sy80zZ/5SZU3a6u+WNu+UrsYzTViuzTqfljZvpTmutxHpcrzPlaOndyhZvT9PxPPetMX7eXjq7XaTjAZhto4Nls9ncLg8AKI9QAwBwKSu/SKv3HNGKXYe1YtcRbf7tmIpL3CQKVEmL8EAN7RSjoYmx6psQpSA/Po4BoCY4iwIAJJWGmDV7jmjFriNavuswIcaDfL1t6tM2UkM6xmpopxglxITQGgMAHkSoAYDTVLajJaa0NWZTJUKMl03y9vrjYtymMhfmrn+VzWm6zc30ssvbXE53v/7qr9PmZgPu11N2esXLB/h56+y2URqaGKN+7aMV4s9HLgDUFs6wAHCayM4v0pq9R090JzusjftPHWKaBPjo7HZROqddlM5pF6nOTZvIy4sWBgBAw0KoAYBGKju/SGtPhJjluw5r0/5jKqpEiOnTNkp9E0pDTKemTZxaZgAAaIgINQDQSOQUFGnNHueWmFOFmNAAH53dtjTAnNMuSp2bEWIAANZDqAEAi8op+KMlZsWuI9qQklHJEBN5ojsZIQYA0DgQagDAInILip26kxFiAAAoRagBgAaqbIhZseuwNuzPUGHxKUKMv4/6lAkxZzQnxAAAGj9CDQA0ELkFxfp53x8hZn1K5UJM77aROqddpPq2iybEAABOS4QaAKgneYXF+nnvUS2vQogJcbTElLbGnNGsiXy8veqoxAAANEyEGgCoI/YQYx/Yvz4lQwXFJRW+JsTfR73bRDi6k3VpTogBAOBkhBoAqCV5hfbuZEdKW2L2nTrEBPt5n+hOFqW+hBgAACqFUAMAHpJXWKx1+zL+6E5WxRBzTrsonUmIAQCgygg1AFBN9hBjH9i/LiVDBUUVh5ggP2/1bmMPMZE6s0WYfAkxAADUCKEGACopr7BY61P+CDE/76tciOnVJlJ9CTEAANQaQg0AuJFf5NwSU5UQY787WVdCDAAAtY5QAwAn5BcVa/2+DMfA/p/3HVX+KUJMoK+3epW5O1lSS0IMAAB1jVAD4LRVVFyidSkZWp5c2hKzdi8hBgAAKyLUADitHM0u0KLtaZq/NVWLtqfpWG5hhcs7h5hIdW0RLj8fQgwAAA0JoQZAo2aM0daDmZq/NVXzt6Zq3b6jKjHulw/w9VKv+D/GxCS1JMQAANDQEWoANDq5BcValpyueVtTtXBrqn4/lud2WV9vm3q3iVS/hChCDAAAFkWoAdAopBzJ0YJtpa0xy5MPVzg2JibUX8MSYzW0U6wGdIhWiD+nQgAArIxPcgCWVFRcorV7j2r+tlQt2Jqq7Yey3C5rs0lJLcM1LDFWwzrFqkvzJvLystVhaQEAQG0i1ACwjCPZBVq0PVXzt6Zp0bZUHc8rcrtsqL+PBnaM1tDEWA1JjFVMqH8dlhQAANQlQg2ABssYo18PZGrBtlTN+/WQ1qdkVDjIv11McGlrTOdY9YqPZGwMAACnCUINgAYlp6BIP+08rPlbU7VwW6oOVDDI38/bS2e3i9SwTqXdyuKjguuwpAAAoKEg1ACodylHchy3XF6+67AKKhjkHxvqr2GdTgzybx+tYAb5AwBw2uNqAECdKzwxyH/BiSCzI7XiQf7dWoY7WmO6NG8im41B/gAA4A+EGgB14kh2gRaeuOXyou1pyjzFIP9BHWM0tFOshiTGKDqEQf4AAMA9Qg2AWmGM0S8HjmvB1lTN25qq9SkZMhUM8k+ICXZ0K+vdJlK+3gzyBwAAlUOoAeAxfwzyP6QFW9N08DiD/AEAQO0j1ACokX2HczR/6yHN35amFacY5B/X5MQg/8RY9WeQPwAA8BCuKABUSWFxidbsOaoFJ8bH7DzFIP/urcI1LLG0WxmD/AEAQG0g1AA4pcNZ+Vq4LU3zt6Vq8akG+QeUDvIfllg6yD+KQf4AAKCWEWoAlGOM0ZbfjzueHbNhf8WD/NvHhji6lfVqE8EgfwAAUKcINQAkSdn5RVq6M10LtqZqwbZUHTqe73ZZPx8vndMuSsNPDPJvFRlUhyUFAABwRqgBTmN7D2c7WmNW7jqigmL3g/ybNgnQ0BMhpn/7KAX5cfoAAAANA1clwGmksLhEq/cc0YITQSY5Ldvtsjab1KNVuOPZMWc0Y5A/AABomAg1QCOXfmKQ/4KtJwb557sf5N/EPsi/U6wGd2SQPwAAsAZCDdDIlB3kP29rqjaeYpB/hxOD/Id1itVZ8RHyYZA/AACwGEIN0AgYY7Rx/zH9b9MB/W/zAaUcyXW7rJ+Pl/q2i9LwzqV3K2OQPwAAsDpCDWBRxhhtsAeZTQe0/6j7INO0SYCGdY7VsMRY9WOQPwAAaGS4sgEsxBij9SkZJ4LMQf2W4T7I9GgdrnM7x2loYqw6NwtlkD8AAGi0CDVAA2eM0bqUDP1v4wHN3uw+yNhsUq/4CF3ctZkuOrOZmoYF1HFJAQAA6gehBmiASkpOBJlNBzR70wH9fizP5XI2m9S7TaRGdG2mC89sqrgmBBkAAHD6IdQADURpkDmq7zYe1OzNB3SggiDTp02kRiQ104VdmiqWIAMAAE5zhBqgHpWUGK3dd1TfbTygOZsP6uBx10HGyyb1aVvaInPBmU0VG0qQAQAAsPNYqMnLy9Ozzz6rTz/9VPv27VNkZKQuvPBCPfHEE2rZsmWV17dz504999xz+uGHH3Tw4EGFhoaqQ4cOuvzyy/XAAw94qthAnSspMVqz92hp17LNB3ToeL7L5bxs0tlto3TxiRaZmFAehAkAAOCKzZiKHstXOXl5eRo+fLiWLVumZs2aaeDAgdqzZ49WrVqlmJgYLV++XAkJCZVe35dffqk//elPys/PV48ePdSxY0cdPnxYmzZtUnBwsHbu3FnTIqtLly6SpC1bttR4XcCpFJcYrdlz5ESQOajUTPdB5px2Ubq4azNdQJABANQyY4w8cCkIOLHZbNW662pNrs890lLzzDPPaNmyZerbt6/mzp2rkJAQSdLkyZN13333acKECVq0aFGl1rVhwwZdddVVCg0N1Q8//KABAwY45pWUlOjnn3/2RJGBWldcYrS6TJBJqyDI9E34I8hEhxBkAAC1p7i4WIcPH1ZmZqYKCgrquzhopPz8/BQaGqqoqCh5e3vX+vZq3FJTWFio2NhYZWRk6Oeff1aPHj2c5nfr1k0bN27UmjVrdNZZZ51yfYMGDdKSJUv0zTffaOTIkTUpWoVoqUFtKC4xWrW7NMjM2eI+yHh72dTX0SITpyiCDACgDhQXF2vfvn3Ky3M9hhPwtICAALVu3bpSwaZeW2qWLl2qjIwMJSQklAs0kjR27Fht3LhR33zzzSlDza+//qolS5aoY8eOtRpoAE8qLjFauftwaZDZfEjpWe6DTL8yLTKRwX51XFIAwOnu8OHDysvLk7e3t+Li4hQcHCwvL6/6LhYamZKSEmVnZ+vQoUPKy8vT4cOHFRsbW6vbrHGo2bBhgySpZ8+eLufbp9uXq8i8efMkSeedd57y8vI0ffp0rVmzRjabTUlJSRo3bpyaNGlS0yIDNVZUXKJVu4/ou00H9P2Wg0rPct187+NlU7/20RrRtanOO4MgAwCoX5mZmZKkuLg4hYWF1XNp0Fh5eXk59q/ff/9dmZmZDT/U7Nu3T5Lc3uHMPt2+XEXsTU2BgYHq3r27tm3b5jT/4Ycf1hdffKFBgwbVpMhAtRQVl2ilPchsPqjD2e6DTP/20RrRtZnOOyNOEQQZAEADYIxxjKEJDg6u59LgdGDfzwoKCmSMqdbNAyqrxqEmKytLkhQUFORyvv3N2JeryNGjRyVJr7zyiiIiIjRz5kwNGzZMhw4d0uOPP65PPvlEo0aN0pYtW9SsWbNKlc/eN+9kycnJVbojG05PRcUlWr7rsP636aC+33JQRyoIMgM6ROvirs10/hlxCg8iyAAAGpayw6jpcoa6UHY/a/Chxn6AuCtkVe5DUFxcLEkqKirSRx99pPPPP1+SFBYWpo8//lg7duzQ6tWr9cYbb+ipp56qYckB1wqLS7Q8uXSMzPdbDupoTqHL5Xy9bRrQ3h5kmiosyLeOSwoAAADJA6EmNDRUkpSdne1yfk5OjiQ5bvNcmXW1aNHCEWjKuvHGG7V69WotXLiw0uVzd/cEdy04OD0VFpdoWfJh/W/jAc39peIgM7BDjC7u2kzndY4jyAAAADQANQ41rVu3liTt37/f5Xz7dPtyFWnTpo0kKT4+vsL5qampVSwlUF5hcYl+2pmu/206oLm/HFKGmyDj5+2lgSe6lp17RpzCAgkyAAAADUmNQ023bt0kye1DMe3Tk5KSTrku+y2hjxw54nL+4cOHJVWu1QdwpaCoRD8lp59okTmkY7nug8ygjn8EmSYBBBkAAICGqsahpn///goLC1NycrLWrVtX7lk1M2bMkKRKPXdm+PDhCg4OVnJyslJSUtSqVSun+fZuZ+5uHw24UlBU2iLz3aYDmrvloI7nFblczs/HS4M6xGhEUlMN70yQAQCgsavqwPX4+Hjt2bOndgpzCm3atNHevXurNF79dFLjUOPn56c77rhDTz/9tO644w7NnTvXccezyZMna+PGjRowYIB69+7teM3rr7+u119/XZdffrmeffZZx/SgoCD97W9/07/+9S/95S9/0fTp0x3rmjNnjj744APZbDbdcsstNS02GrmCohIt3Zmm7zYe1A+/VBxkhnSM0YikZhrWKVahBBkAAE4b48ePLzdt6dKlSk5OVrdu3dS9e3enedHR0bVSjj179qht27YaPHhwlcaO4w81DjWS9Mgjj+jHH3/UsmXL1KFDBw0cOFB79+7VypUrFRUVpSlTpjgtn56erm3btunAgQPl1vXYY49pyZIl+u6779ShQwedffbZSk1N1YoVK1RSUqKnn35affr08USx0cjkFxVr6Y7SFpkffjmkTDdBxt/HS0MSSwf7D+8cpxB/jxwGAADAYqZOnVpu2g033KDk5GSNGjVKkyZNqvMyuTNv3jwVFrruNg8PhZqAgAAtWLBAzz77rD755BPNmjVLERERGj9+vJ588sly3chOta758+frxRdf1EcffaTZs2crICBAQ4cO1T333KMRI0Z4oshoJPKLirVke+lg/x9+OaTMfPdBZmhirC4+0SJDkAEAAFbC8xUr5rEnLwUGBuqJJ57Qzp07lZ+fr4MHD2rq1KkuA82kSZNkjHGZjqXSLm1///vf9csvvygvL08ZGRn68ccfCTSQJOUVFmvuloO6Z/p69XryR9304RrNXPdbuUAT4Ouli85sqteu7qGfHz1Pb193li7t1pxAAwAAqqWgoECvvvqqevfurdDQUAUHB6tPnz56//33XY51SUlJ0e23367ExEQFBQUpMjJSXbp00a233qpt27ZJKr0ubtu2rSRp0aJFstlsjp8bbrjBsa42bdqUGwO0Z88e2Ww2DRkyRLm5uZo4caLi4+Pl7++v9u3b67nnnnM7BmfevHkaNGiQgoODFRUVpTFjxmjHjh2aNGmSbDab2+v0hoqrO1hCYXGJFmxN1XebDmjer6nKctMiE+DrpWGdYnVx12YamhirYAIMAADwgOzsbF100UVasmSJoqOjNWDAAHl5eWn58uW66aabtHr1ar399tuO5ffv36+ePXsqPT1dSUlJuuSSS5SXl6e9e/fq3XffVd++fZWYmKju3btrzJgx+uKLLxQXF6cLL7zQsY4BAwZUqmwFBQU6//zztWXLFvXp00edO3fWokWLNHHiRGVmZpZ7aP0XX3yhcePGqaSkRP3791erVq20Zs0a9enTR5deeqlnKqyOccWHBi2vsFifr0nR24t26beMXJfLBPp6/xFkOsUoyI/dGgCAqjLGuL2xTkPWJMCnyncxq44HHnhAS5Ys0XXXXac333zT8YiRtLQ0XXLJJXrnnXd0ySWXOHoWvffee0pPT9dLL72ke++912lde/fuVVFRaV2PGjVK3bt31xdffKFOnTpVq4Vk+fLlGjhwoLZv3+64mcGaNWvUt29fvfzyy5o4caKjvMeOHdMtt9yikpISffbZZ7riiiskScXFxfrLX/6id999t1r1U9+4+kODlJVfpI9X7NW7S3YrPSu/3PxAX28N6xyrESdaZAL9vOuhlAAANB7H84rU7fG59V2MKtvw2Pm1/mDs1NRUvffee2rbtq3effdd+fv7O+bFxMTonXfeUffu3fXOO+84Qo39YfHDhg0rtz53D5qvLi8vL7333ntOd2fr1auXLrroIn3zzTdas2aNhgwZIkn6/PPPdeTIEV1wwQWOQCNJ3t7eevHFFzVt2jRlZmZ6tHx1gVCDBuVodoGmLtujqcv2lHswpo+XTRec2VQjuzbTEIIMAACoI4sWLVJhYaEuvPBCp0Bj161bN4WGhmr16tWOaWeddZYk6fbbb9dTTz2lgQMHysendi6927Rpo44dO5abbp9W9o7Dy5YtkySnQGPXpEkTnX/++friiy9qpZy1iVCDBiH1eJ7eXbJLH6/cp5yCYqd5/j5euqp3K908qJ1aRgTVUwkBAMDpyv7AzbfeektvvfWW2+Vyc//oKn/DDTdo7ty5+uyzzzRs2DAFBQU5Wk8mTJig2NhYj5WvZcuWLqfbu5zl5//R6+X333+XJLd3J27durXHylWXCDWoVylHcvT2omR9vna/CopKnOaF+Pvo2nPi9ecBbRUTWv5bEQAA4DlNAny04bHz67sYVdYkoPYvZ4uLS79w7dGjh5KSkir1Gm9vb02fPl0TJ07UV199pQULFmjFihVavHixnn32WX3//fc655xzPFK+6owpcvcad3dLa+gINagXO1Mz9eaCZH214XcVlzgfPOFBvprQv63G922jsKDa7SMLAABK2Wy2Wh+bYlX2lpAhQ4Zo8uTJVXptjx491KNHD02aNEnHjx/X448/rsmTJ+uuu+7SypUra6O4FWrWrJkkad++fS7np6Sk1GVxPMZjz6kBKmPT/mO67b9rdd7LizVz3W9OgSY21F+PjOisnx4apjuHdyDQAACABmHo0KHy9vbWt99+62i1qY4mTZromWeekc1m06ZNmxzT/fz8JMlxR7Ta1K9fP0nSjBkzys07fvy4fvjhh1ovQ20g1KBOrNx1WNf/Z5UueX2p5mw5qLItm60jg/TM5V215KGhumlgO54tAwAAGpQWLVrohhtu0I4dO3TdddcpPT293DLLli3T//73P8f///vf/2rz5s3llpszZ46MMU5jV6Kjo+Xr66vk5OQahabKuOKKKxQREaE5c+Y43RCgpKREDz30kI4fP16r268tXD2i1hhjtHB7mt5csFOr9xwtN79DbIhuH9peI5OaycebfA0AABquf//739q1a5c+/fRTffvtt+revbuaN2+ugwcPaufOnfrtt99011136eKLL5ZU+oDL66+/XgkJCeratasCAwO1Z88erVixQt7e3nrmmWcc6/bz89OFF16ob775Rt26dVPPnj3l5+en/v3768Ybb/To+wgPD9fbb7+tq6++WmPHjtWAAQMcD99MTU3Vtddeq48++sjRemQVhBp4XHGJ0fdbDuqNBTu15ffyaT+pZZhuH9pe53WOk5dX7T8sCwAAoKaCgoI0d+5cffDBB/rvf/+rjRs3auXKlYqNjVVCQoLuuusuXX311Y7l7733XrVs2VI//fSTlixZouzsbLVo0UJXX3217r//fvXo0cNp/e+9957uv/9+/fDDD/rkk09UXFysoqIij4caSRo3bpwiIiL0xBNPaO3atdq8ebMGDx6sb775Ri+++KIkKSoqyuPbrU02Y9VbHNRQly5dJElbtmyp55I0HoXFJfpq/e96a+FOJadll5t/TrtI3T60vQa0j66TJ/8CAIA/lJSUaNu2bZKkxMREeXnRSwLOSkpKlJSUpC1btujAgQNq2rRpjddXlX2uJtfntNSgxvIKi/X5mhS9vWiXfsvILTd/WKdY3T40QWfFR9ZD6QAAAFDWb7/9Jl9fX6dn5RQWFuqRRx7Rli1bNGzYsBoHmrpGqEG1ZeUX6aMVe/Xekt1Kz8p3mmezSRd3baa/DklQl+Zh9VRCAAAAnGzJkiW69tpr1bNnT8XHxys7O1sbNmzQ77//rsjISL322mv1XcQqI9Sgyo5mF2jKsj36YNkeHcstdJrn42XT5T1a6C9DEtQuJqSeSggAAAB3zjrrLF133XVasmSJfv31VxUUFKh58+a65ZZb9PDDD6tNmzb1XcQqI9Sg0lKP5+ndJbv08cp9yilwvt2gv4+XrurdSrcMTlCL8MB6KiEAAABOpUOHDpoyZUp9F8OjCDU4pZQjOXp7UbI+X7NfBcUlTvNC/H10Xd94TejfVjGh/vVUQgAAAJzOCDVwa8ehTL21MFlfbfhdxSXON8mLCPLVhP5tdX3fNgoL8q2nEgIAAACEGriwaf8xvbFgp+ZsOVhuXlwTf908sJ2u7tNawf7sPgAAAKh/XJVCkmSM0ardR/T6gp1asiO93PzWkUG6bXCCxpzVQv4+3vVQQgAAAMA1Qs1pzhijhdvT9Mb8nVqz92i5+R3jQvTXIe01MqmZfLx5SBcAAAAaHkLNaaq4xGjO5oN6Y8FO/XLgeLn53VqG6fah7XVu5zh5ednqoYQAAABA5RBqTjOFxSWate43vbUoWbvSssvNP6ddpO4Y2kH920fJZiPMAAAAoOEj1Jwm8gqL9dmaFL2zaJd+y8gtN39Yp1jdPjRBZ8VH1kPpAAAAgOoj1DRymXmF+njlPr23ZLfSs/Kd5tls0oiuzfSXIQnq0jysnkoIAAAA1AyhppE6ml2gKcv2aOpPu3U8r8hpno+XTaN7ttBtgxPULiaknkoIAABQv6ra1T4+Pl579uzxaBmGDBmiRYsWaffu3WrTpk2DWZfVEGoamUPH8/Tekl36eOU+5RQUO83z9/HS1X1a6+ZB7dQiPLCeSggAANAwjB8/vty0pUuXKjk5Wd26dVP37t2d5kVHR9dRyVBVhJpGYt/hHL29OFkz1uxXQXGJ07wQfx9d1zdeE/q3VUyofz2VEAAAoGGZOnVquWk33HCDkpOTNWrUKE2aNKnWy/Dhhx8qJydHLVq0aFDrshpCjcXtOJSpNxcm6+sNv6u4xDjNiwjy1YT+bXV9vzYKC/StpxICAADAndatWzfIdVkNT1O0qI37M3Trf9fovJcX68t1vzkFmrgm/np05Bn6aeIw/W14BwINAABADS1cuFA2m0033HCDDh48qJtuukktW7aUj4+PXnnlFUnSgQMH9Pzzz2vw4MFq0aKF/Pz81LRpU40ePVqrV692ud4hQ4bIZrOVG6tjs9nUpk0bFRcX6/nnn1fHjh3l7++vVq1a6aGHHlJ+fn6trkuS1q1bp4suukhhYWEKCwvTBRdcoNWrV2vq1Kmy2Wx10pJVWbTUWIgxRit3H9EbC3ZqyY70cvNbRwbpL0MSNLpnC/n7eNdDCQEAABq3tLQ09e7dW0VFRRowYIDy8vIUFBQkSfrqq6/00EMPqX379uratauaNGminTt36ssvv9S3336rb7/9Vueff36VtnfNNdfo22+/VZ8+fZSYmKglS5bo+eef12+//aaPPvqo1ta1bNkynXvuucrNzVWPHj2UmJioX375RQMGDNCNN95Ype3WBUKNBRhjtHBbmt5YsFNr9h4tN79jXIhuH9peI7o2k483jW8AAKAajJHyjtV3KaouIKz0ORV15H//+58uv/xyffLJJwoICHCa179/f23YsEFJSUlO07///ntdeuml+utf/6odO3ZU+q5re/fuVVBQkDZv3uy4m9nu3bt11lln6eOPP9bjjz+uhIQEj6+rpKREN954o3Jzc/X888/rgQcecKznySef1D//+c9KbbMuEWoasOISozmbD+qNBTv1y4Hj5eZ3axmm24e217md4+TlVXcHMwAAaITyjknPxdd3Karuob1SYHidbc7f31+vvfZauUAjSV27dnX5mgsuuEBXXHGFPv74Y23evNntcq689tprTrdnbtu2ra699lq99tprWrJkSaVDTVXWNX/+fG3fvl2dOnXS/fff77SOv//975oyZYp2795d6e3WBUJNA1RYXKJZ637TW4uStSstu9z8vu2idPvQ9urfPqrK91cHAABA9fXs2bPCu4vl5+drzpw5WrVqldLS0lRQUCBJ2rRpkyRpx44dlQ41vr6+GjJkSLnpHTt2lFQ6hqeyqrKuZcuWSZLGjh1b7lrT29tbo0eP1ksvvVTpbdcFQk0DkldYrOmrU/R/i3fpt4zccvOHd4rVX4e211nxEfVQOgAAAFR0h7FNmzbp0ksvrfABnZmZmZXeVrNmzeTtXX6cdEhI6cPT3Q3wr+m6fv/9d0lSq1atXK6rId5ljVDTAGTmFeqjFfv0/tJdSs8qcJpns0kjujbTX4e01xnNm9RTCQEAQKMXEFbalctqAsLqdnMuup1JpWOgx40bpz179ui2227Tbbfdpnbt2ikkJEQ2m01///vf9eyzz8oY4/L1rniyR0511uXuNVV5D3WFUFOPjmYXaMpPuzV12R4dzytymufjZdPoni102+AEtYsJqacSAgCA04bNVqdjUxqbrVu3auvWrerVq5feeuutcvN37dpVD6WqnmbNmkmS9u3b53J+SkpKXRanUgg19eSHXw7prmnrlFNQ7DQ9wNdLV/VurZsHtVOL8MB6Kh0AAACq4ujR0jvUtmzZ0uW8H374oa6LVG39+vWTJH3xxRd64oknnFpsSkpK9OWXX9ZX0dzi/r/1pGuLMBUV/9F0F+rvo78OSdDSh4Zp0qVdCDQAAAAW0r59e3l5eWn+/PnasWOHY3peXp5uu+02HTlypB5LVzXDhg1T+/bt9euvv+rll192mvevf/2rQbY6EWrqSdOwAI05q6Uignx1//kdtXTiMD14YSdFh/jXd9EAAABQRbGxsfrzn/+s48ePq1u3bho5cqSuuOIKtWnTRvPnz9cNN9xQ30WsNG9vb02ZMkUBAQG67777dNZZZ+lPf/qTunfvrscff1w333yzJMnPz6+eS/oHQk09euCCRP00cZjuGNZBYYG+9V0cAAAA1MBbb72ll156SW3bttW8efO0ZMkSnXvuuVqzZo3i4631DKABAwZo6dKluuCCC7Rjxw59++23io6O1qJFixzvJSoqqp5L+QebaYi3L6gDXbp0kSRt2bKlnksCAABQ+0pKSrRt2zZJUmJiory8+G4b1XPRRRdpzpw5WrFihc4++2y3y1V1n6vJ9Tl7MwAAAAAnR44c0d69zrf4Nsbotdde05w5c9S+fXv16dOnnkpXHnc/AwAAAOBk+/bt6tevn5KSktSuXTsVFxdr8+bN2rVrlwIDA/Xuu+969Dk6NUVLDQAAAAAn7dq102233ab8/HzNmzdPs2fPVn5+vv70pz9p5cqVGjJkSH0X0QktNQAAAACcxMbG6s0336zvYlQaLTUAAAAALI1QAwAAAMDSCDUAAAAALI1QAwAAcBooe6eqkpKSeiwJThdl97PavlMaoQYAAOA0YLPZ5OfnJ0nKzs6u59LgdGDfz/z8/Go91HD3MwAAgNNEaGioDh8+rEOHDkmSgoODT/mUd6CqSkpKlJ2d7djPQkNDa32bhBoAAIDTRFRUlLKzs5WXl6fff/+9vouD00BAQICioqJqfTuEGgAAgNOEt7e3WrdurcOHDyszM1MFBQX1XSQ0Un5+fgoNDVVUVJS8vb1rfXuEGgAAgNOIt7e3YmNjFRsbK2OMjDH1XSQ0MjabrdbH0JyMUAMAAHCaqo+LT6A2MDIMAAAAgKURagAAAABYGqEGAAAAgKURagAAAABYGqEGAAAAgKURagAAAABYms2cpjcnDw0NVWFhoRISEuq7KAAAAMBpLzk5Wb6+vsrMzKzya0/blprg4GD5+vrWdzGUnJys5OTk+i6GJVBXlUddVR51VXnUVeVRV5VHXVUN9VV51FXlNZS68vX1VXBwcLVee9q21DQUXbp0kSRt2bKlnkvS8FFXlUddVR51VXnUVeVRV5VHXVUN9VV51FXlNYa6Om1bagAAAAA0DoQaAAAAAJZGqAEAAABgaYQaAAAAAJZGqAEAAABgadz9DAAAAICl0VIDAAAAwNIINQAAAAAsjVADAAAAwNIINQAAAAAsjVADAAAAwNIINQAAAAAsjVADAAAAwNIINR6Ul5enxx57TB07dlRAQICaN2+uCRMmaP/+/VVaT5s2bWSz2dz+bN26tZbegefVZ53ccMMNFb7m7bff9tTbrHWeqke7nTt36uabb1abNm0UEBCgmJgY9evXTy+88IKHS1476rM+2K+cTZ06tcL6sP98+OGHtfhOPKM+64P9yrU5c+booosuUnR0tHx9fRUbG6uRI0dq3rx5tVDy2lOfdcK+5drs2bN13nnnKTw8XEFBQeratateeOEFFRUV1ULJa0d91kdD3K986nyLjVReXp6GDx+uZcuWqVmzZrrsssu0Z88eTZkyRd9++62WL1+uhISEKq1z/PjxLqeHhYV5osi1rqHUyQUXXKCmTZuWm56YmFilbdcXT9fjl19+qT/96U/Kz89Xjx491LdvXx0+fFibNm3SO++8owceeKAW303NNZT6YL8q1b59e7fH5bFjxzRr1ixJ0oABAzxZfI9rKPXBfvWHyZMn67777pPNZlP//v3VokUL7dq1S999952+++47vfXWW7rttttq+R3VXEOpE/atPzz33HOaOHGivLy8dPbZZysmJkYrVqzQgw8+qB9//FHfffedfHwa9iVyQ6mPBrVfGXjEo48+aiSZvn37mszMTMf0l156yUgygwYNqvS64uPjTWP409R3nYwfP95IMgsWLKjS6xoaT9bj+vXrjZ+fn4mKijJLlixxmldcXGxWr17tsXLXlvquD/arynvzzTeNJNO/f/8ar6u21Xd9sF85S01NNX5+fsbPz6/csTljxgxjs9lMUFCQ0zYaqvquE/YtZ6tWrTI2m834+vqa77//3jE9IyPDDBo0yEgy//rXvzxefk+r7/poiPuV9a+cG4CCggITHh5uJJmff/653PykpCQjyaxZs6ZS62sMoaYh1ElDPOCqytP1OHDgQCPJfPPNN54uap1oCPXBflV5/fr1M5LM22+/XaP11LaGUB/sV86++eYbI8lceOGFLud369bNSDIrV66scblrU0OoE/YtZ3/+85+NJHPzzTeXm7d582YjycTExJiioiKPlL02NIT6aIj7FWNqPGDp0qXKyMhQQkKCevToUW7+2LFjJUnffPNNXRet3lAnnuHJevz111+1ZMkSdezYUSNHjvR4WesC9eEZdXF87t69W8uWLZOfn5/GjRtX7fXUBerDMzxZj/7+/pXaZmRkZNUKWceoE8/wZD2uXbtWkjRkyJBy87p06aLo6GilpaVp2bJlNSt0LaI+XGvYHQYtYsOGDZKknj17upxvn25frrJeeOEFJScny9/fX126dNHll1+umJiYmhW2jjSkOpk5c6a++OILFRcXq23btrrkkkvUqVOnKm23vniyHu2DSM877zzl5eVp+vTpWrNmjWw2m5KSkjRu3Dg1adLEQyWvHQ2pPtivKvbRRx9JkkaMGKGIiIhqr6cuNKT6YL8q1bt3b4WFhWn+/PlaunSp0xikmTNnauPGjerXr5/at2/vgZLXnoZUJ+xbpbKzsyXJ7XEYGRmp9PR0bdiwQQMHDqxOcWtdQ6qPhrRfEWo8YN++fZKkli1bupxvn25frrIefPBBp//fc889+ve//60///nP1Shl3WpIdfLaa685/f+hhx7SX/7yF7366qsNfiCgJ+txy5YtkqTAwEB1795d27Ztc5r/8MMP64svvtCgQYNqUuRa1ZDqg/2qYh9//LEk6brrrqv2OupKQ6oP9qtS4eHheu+993TNNddo0KBBjkHxu3fv1urVq3XhhRdq6tSpHit7bWlIdcK+VSomJkY7duzQ3r17y80rKSlRSkqKJGnPnj3VLG3ta0j10ZD2K7qfeUBWVpYkKSgoyOX84OBgp+VO5dJLL9XMmTO1d+9e5eTkaPPmzbr33nuVn5+vm266yXH3nIasIdRJjx499Pbbb2v79u3KycnRrl279MYbbyg8PFxvvvlmg7/Ll+TZejx69Kgk6ZVXXtGRI0c0c+ZMZWRkaNu2bfrTn/6k9PR0jRo1SgcOHPBQ6T2vIdQH+9WprVq1Stu2bVNERIRGjBhRvULWoYZQH+xX5Y0dO1azZ89WVFSUli5dqunTp2vVqlWKjY3VsGHDFBUV5ZmC16KGUCfsW84GDx4sSfrggw/KzZs+fbpyc3MlSZmZmdUqa11oCPXRIPer+h7U0xjcdNNNRpJ55JFHXM7fvn27kWQ6duxYo+288847HllPXWjIdbJp0ybj5+dnvL29zb59+2q0/drmyXocO3askWQkOd3hxK53795GkvnHP/5R43LXloZcH6frfuXK3/72NyPJ3HbbbTUpZp1pyPVxOu9XL774ovHy8jKjR482GzduNFlZWWbjxo1m1KhRRpIZM2aMJ4tfKxpynZyu+9b+/ftNWFiYkWTGjx9vduzYYY4ePWqmTZtmIiIijI+PT4M/fzXk+qjP/YqWGg8IDQ2V9Ee/xJPl5ORIkkJCQmq0nZtuukmxsbHavn27du/eXaN11baGXCdnnnmmLr30UhUXF+vHH3+s0fZrmyfr0b6uFi1a6Pzzzy83/8Ybb5QkLVy4sDpFrRMNuT5O1/3qZEVFRZo+fboka3Q9kxp2fZyu+9WiRYt0//33q3v37vr888/VtWtXBQcHq2vXrpoxY4Z69OihL774QnPnzvXcG6gFDblOTtd9q0WLFvryyy8VGRmpDz74QB06dFBERISuuuoqtWrVShMmTJDkfoxJQ9CQ66M+9ytCjQe0bt1aktw+wdU+3b5cdXl5eTkepNSQuwhJDb9OOnToUOXX1AdP1mObNm0kSfHx8RXOT01NrWIp605Dr4/Tcb862dy5c5Wamqp27dqpX79+1S9kHWro9XE67lcffvihJGn06NHy8nK+VPH29tbo0aMlNewvYaSGXyen474lSUOHDlVycrLefvtt/fWvf9Udd9yh//73v1q1apUyMjIkld75q6Fq6PVRX/tVwx4ZZhHdunWTJP38888u59unJyUl1Xhb9nEANW3hqG0NvU5Ox3q03/bxyJEjLucfPnxYUsOuk4ZeH6fjfnUy+12+rr322mqWru419Po4Hfcr+0WZuzsQ2qe7O34bioZeJ6fjvmUXHh6uW2+91WlaUVGRFi1aJC8vrwZ905yGXh/1tl/VaWe3Rio/P9/RH7GihyCtWrWqRtvZvHmz44nB+fn5NVpXbWvIdZKXl2datWplJJmlS5fWaPu1zZP1mJ2dbYKDg42vr6/Lfq72B3D9+c9/9kjZa0NDro/Tdb8qKzMz0wQFBRlJZvv27Z4qbq1ryPVxuu5X119/vZFkrr/+epfzr732WiPJPPvsszUud21qyHVyuu5bFZk6daqRZC6++OIarae2NeT6qM/9ilDjIf/4xz+MJNOvXz+TlZXlmP7SSy8ZSWbAgAFOy7/22msmMTHRTJw40Wn6nDlzXD4BdsOGDaZz585Gkrnzzjtr5014WH3WydatW82sWbPKPQE3NTXVMaCyW7dupqSkpKZvs9Z5qh6NMWbixIlGkhkxYoTTumbPnm18fHyMzWZr8E/ors/6YL9yXY92H3zwgZFkzjnnnFord22pz/pgvypfjzNnzjSSjLe3t/n666+d5s2aNct4eXkZLy8vs3Xr1tp7Mx5Sn3XCvuX6GF2zZk259zx37lwTGhpqAgICTqv9ypiq10dD3a8INR6Sm5trzj77bCPJNGvWzIwbN87x/6ioKLNjxw6n5R977DHHnSZcTY+PjzfDhg0zV155penTp4/j7hODBw822dnZdfjOqq8+62TBggWO7fTv39+MGzfODBkyxISGhhpJpmXLlmbbtm21XQUe4al6tK+rf//+jnWNGjXK9OvXz3h5eRlJ5umnn66jd1V99Vkf7Feu69HuvPPOM5LMG2+8Ucul97z6rA/2q/L1WFJSYq644gojld6hsFevXuaKK64wvXr1ckyzwvnKmPqtE/Yt18dofHy8admypbnooovMVVddZXr06GEkmcDAQPPtt9/W0Tuqmfqsj4a6XxFqPCgnJ8c8+uijJiEhwfj5+Zm4uDgzfvx4l11b3O1cy5YtMxMmTDBdu3Y1UVFRxsfHx0RGRpohQ4aYd999t1wqbujqq05+++03c/fdd5tzzjnHNG3a1Pj6+pqQkBDTs2dP89hjj5kjR47U1luuFZ6oR7v8/Hzz9NNPm86dOxt/f38TFhZmhg8fbpkTuTH1Vx/sV+7r8ffffzfe3t7G19fXpKen13LJa0d91Qf7let6LCkpMe+//74ZNGiQCQ8PNz4+PiY6OtpcfPHFZvbs2XXwTjynvuqEfct1PT777LPm7LPPNpGRkcbPz8/Ex8ebW265xSQnJ9fBu/Cc+qqPhrpf2YwxRgAAAABgUdzSGQAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWBqhBgAAAIClEWoAAAAAWNr/A9Xrzn+0imPoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias_variance_plot(test_bias,train_bias,train_split_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
